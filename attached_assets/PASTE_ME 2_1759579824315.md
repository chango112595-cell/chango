# PASTE_ME.md — Chango AI Reply-Fix (Complete, Isolated)

This file includes **all modules** required for reliable voice replies: DebugBus, mic permissions, wake-word gate, STT, TTS, always-listen controller, LLM orchestrator, compact header, sticky chat dock, layout CSS, and example `App.tsx` wiring.

---

## File Map

```
client/
  components/
    AudioUnlock.tsx
    ChatInputBar.tsx
    HeaderCompact.tsx
  lib/
    permissions.ts
    useViewportVh.ts
  styles/
    layout.css
  voice/
    stt.ts
    tts.ts
    alwaysListen.ts
    gate.ts
  debug/
    DebugBus.ts
  llm/
    orchestrator.ts
App.tsx
```

---

## client/debug/DebugBus.ts
```ts
type Level = 'ok'|'info'|'warn'|'error';
type Event = { tag: string; level: Level; msg: string; data?: any; ts?: number };

const flags = new Map<string, boolean>();
const listeners = new Set<(e: Event) => void>();

export const DebugBus = {
  on(fn:(e:Event)=>void){ listeners.add(fn); return ()=>listeners.delete(fn); },
  emit(e: Event){
    e.ts = e.ts || Date.now();
    for (const fn of Array.from(listeners)) try{ fn(e); }catch{}
    const line = `[${new Date(e.ts).toISOString()}] [${e.level}] ${e.tag}: ${e.msg}`;
    if (e.level==='error') console.error(line, e.data||'');
    else if (e.level==='warn') console.warn(line, e.data||'');
    else console.log(line, e.data||'');
  },
  defineFlags(names: string[]){ names.forEach(n=>flags.set(n, false)); },
  flag(name: string, val: boolean){ flags.set(name, val); DebugBus.emit({tag:'FLAG', level:'info', msg:`${name}=${val}`}); },
  snapshot(){ return Object.fromEntries(flags.entries()); }
};
```

---

## client/lib/permissions.ts
```ts
export type MicState = 'unknown'|'granted'|'denied'|'blocked'|'prompt';

let audioUnlocked = false;

export async function unlockAudioContext(ctx: AudioContext) {
  if (ctx.state === 'suspended') await ctx.resume();
  audioUnlocked = true;
}

export async function checkMicPermission(): Promise<MicState> {
  try {
    // @ts-ignore
    if (navigator.permissions?.query) {
      // @ts-ignore
      const status = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      if (status.state === 'granted') return 'granted';
      if (status.state === 'denied')   return 'denied';
      return 'prompt';
    }
  } catch {}
  try {
    const s = await navigator.mediaDevices.getUserMedia({ audio: true });
    s.getTracks().forEach(t => t.stop());
    return 'granted';
  } catch (e:any) {
    const name = e?.name || '';
    if (name === 'NotAllowedError' || name === 'SecurityError') return 'denied';
    if (name === 'NotFoundError') return 'blocked';
    return 'prompt';
  }
}

export async function requestMicStream(): Promise<MediaStream> {
  return navigator.mediaDevices.getUserMedia({
    audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true, channelCount: 1, sampleRate: 44100 }
  });
}

export function isAudioUnlocked(){ return audioUnlocked; }
```

---

## client/voice/gate.ts
```ts
import { DebugBus } from '../debug/DebugBus';
let enabled = false;
let wake = 'lolo';
export const VoiceGate = {
  enable(word: string){ enabled = true; wake = (word||'lolo').toLowerCase(); DebugBus.flag('Gate', true); },
  disable(){ enabled = false; DebugBus.flag('Gate', false); },
  check(txt: string){
    if (!enabled) return { pass: true, cmd: txt };
    const raw = (txt||'').toLowerCase();
    const i = raw.indexOf(wake);
    if (i === -1) return { pass: false, cmd: '' };
    const cmd = raw.slice(i + wake.length).replace(/^[\s,.:;-]+/, '');
    return { pass: !!cmd, cmd };
  }
};
```

---

## client/voice/stt.ts
```ts
import { DebugBus } from '../debug/DebugBus';
import { VoiceGate } from './gate';
import { speak } from './tts';
import { sendToLLM } from '../llm/orchestrator';

let recognizer: SpeechRecognition | null = null;

export async function startSTT() {
  stopSTT();
  const SR = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
  if (!SR) throw new Error('no_speech_recognition');

  recognizer = new SR();
  recognizer.lang = 'en-US';
  recognizer.continuous = true;
  recognizer.interimResults = true;

  recognizer.onresult = async (ev: SpeechRecognitionEvent) => {
    let finalTxt = '';
    for (let i = ev.resultIndex; i < ev.results.length; i++) {
      const r = ev.results[i];
      if (r.isFinal) finalTxt += r[0].transcript;
    }
    if (!finalTxt) return;

    const raw = finalTxt.trim();
    DebugBus.emit({ tag:'STT', level:'info', msg:`heard="${raw.toLowerCase()}"` });

    const check = VoiceGate.check(raw);
    if (!check.pass) { DebugBus.emit({ tag:'Gate', level:'info', msg:'ignored (no wake word)' }); return; }

    const reply = await sendToLLM(check.cmd);
    DebugBus.emit({ tag:'Orch', level:'ok', msg:`reply="${(reply||'').slice(0,80)}..."` });
    await speak(reply);
  };

  recognizer.onerror = (e:any) => {
    DebugBus.emit({ tag:'STT', level:'error', msg: e?.error || 'stt_error' });
  };
  recognizer.onend = () => {
    DebugBus.emit({ tag:'STT', level:'warn', msg:'recognizer ended – auto-restart' });
    try { recognizer?.start(); } catch {}
  };

  try { recognizer.start(); DebugBus.emit({ tag:'STT', level:'ok', msg:'recognizer started' }); }
  catch (e:any) { DebugBus.emit({ tag:'STT', level:'error', msg:`start failed: ${e?.message||e}` }); throw e; }
}

export function stopSTT() {
  try { recognizer?.stop(); } catch {}
  recognizer = null;
}
```

---

## client/voice/tts.ts
```ts
import { DebugBus } from '../debug/DebugBus';
let utter: SpeechSynthesisUtterance | null = null;
let speaking = false;
export async function speak(text: string){
  if (!('speechSynthesis' in window)) { DebugBus.emit({ tag:'TTS', level:'warn', msg:'No Web Speech Synthesis' }); return; }
  try {
    if (speaking && utter) { window.speechSynthesis.cancel(); speaking = false; }
    utter = new SpeechSynthesisUtterance(text || '');
    utter.rate = 1.0; utter.pitch = 1.0; utter.volume = 1.0;
    utter.onstart = () => { speaking = true; DebugBus.flag('TTS', true); };
    utter.onend = () => { speaking = false; DebugBus.flag('TTS', false); };
    utter.onerror = (e:any) => { speaking = false; DebugBus.emit({ tag:'TTS', level:'error', msg: e?.error || 'tts_error' }); };
    window.speechSynthesis.speak(utter);
  } catch (e:any) { DebugBus.emit({ tag:'TTS', level:'error', msg: e?.message || 'tts_failed' }); }
}
export function stopSpeak(){ try { window.speechSynthesis.cancel(); } catch {} speaking = false; DebugBus.flag('TTS', false); }
```

---

## client/voice/alwaysListen.ts
```ts
import { checkMicPermission, requestMicStream, unlockAudioContext } from '../lib/permissions';
import { DebugBus } from '../debug/DebugBus';
import { startSTT, stopSTT } from './stt';
import { VoiceGate } from './gate';

let running = false;
let ctx: AudioContext | null = null;

export async function ensureAudioUnlocked() {
  if (!ctx) ctx = new (window.AudioContext || (window as any).webkitAudioContext)();
  await unlockAudioContext(ctx);
}

export async function startAlwaysListen({ wakeWord = 'lolo', enabled = true } = {}) {
  if (running || !enabled) return;
  try {
    await ensureAudioUnlocked();
    const state = await checkMicPermission();
    DebugBus.emit({ tag:'AlwaysListen', level:'info', msg:`Permission state: ${state}` });
    if (state === 'denied' || state === 'blocked') throw new Error('mic_denied');
    const s = await requestMicStream(); s.getTracks().forEach(t => t.stop());
    VoiceGate.enable(wakeWord);
    await startSTT();
    running = true;
    DebugBus.flag('STT', true);
    DebugBus.flag('Gate', true);
  } catch (e:any) {
    running = false;
    DebugBus.flag('STT', false);
    DebugBus.flag('Gate', false);
    DebugBus.emit({ tag:'AlwaysListen', level:'error', msg:`Startup failed: ${e?.message||e}` });
  }
}

export async function stopAlwaysListen() {
  try { VoiceGate.disable(); await stopSTT(); }
  finally { running = false; DebugBus.flag('STT', false); DebugBus.flag('Gate', false); }
}
```

---

## client/llm/orchestrator.ts
```ts
export async function sendToLLM(q: string): Promise<string> {
  const t = q.toLowerCase().trim();
  if (/time/.test(t)) {
    const now = new Date();
    return `The current time is ${now.toLocaleTimeString([], {hour:'2-digit', minute:'2-digit'})}.`;
  }
  if (/date/.test(t)) {
    const now = new Date();
    return `Today is ${now.toLocaleDateString()}.`;
  }
  if (/who\s*are\s*you/.test(t) || /your name/.test(t)) return "I'm Chango, your AI system — online and listening.";
  return "Got it. What else would you like to try?";
}
```

---

## client/components/HeaderCompact.tsx
```tsx
import React from 'react';
export default function HeaderCompact({ version = 'v-current' }: { version?: string }) {
  return (
    <header className="hc">
      <div className="hc__left">
        <span className="hc__dot" />
        <span className="hc__title">Chango AI</span>
      </div>
      <div className="hc__spacer" />
      <div className="hc__pill" title="System online">{version}</div>
    </header>
  );
}
```

---

## client/components/ChatInputBar.tsx
```tsx
import React, { useState } from 'react';
export default function ChatInputBar({ onSend }:{ onSend:(msg:string)=>void }) {
  const [msg, setMsg] = useState('');
  const send = () => { const t = msg.trim(); if (!t) return; onSend(t); setMsg(''); };
  return (
    <div className="chatdock" role="region" aria-label="Chat input">
      <input className="chatdock__field" value={msg} onChange={e=>setMsg(e.target.value)} onKeyDown={e=>e.key==='Enter' && send()} placeholder="Ask Chango…" />
      <button className="chatdock__send" onClick={send} aria-label="Send">➤</button>
    </div>
  );
}
```

---

## client/components/AudioUnlock.tsx
```tsx
import React from 'react';
import { ensureAudioUnlocked } from '../voice/alwaysListen';
export function AudioUnlock() {
  const [ok, setOk] = React.useState<boolean>(() => !!sessionStorage.getItem('audio_unlocked'));
  if (ok) return null;
  return (
    <button
      onClick={async () => {
        await ensureAudioUnlocked();
        sessionStorage.setItem('audio_unlocked','1');
        setOk(true);
      }}
      className="rounded-full px-3 py-1 text-xs bg-emerald-600/20 border border-emerald-500"
      style={{ position:'fixed', right:12, bottom:88, zIndex:1000 }}
    >
      Enable Audio
    </button>
  );
}
```

---

## client/styles/layout.css
```css
:root{ --hud-z:40; --sphere-z:20; --debug-z:30; --chat-z:100; --safe-bottom: env(safe-area-inset-bottom, 0px); }
html, body, #root { height: 100%; }
.app { min-height: 100dvh; display: flex; flex-direction: column; padding-bottom: calc(70px + var(--safe-bottom)); }
.hc{ position: sticky; top: 0; z-index: var(--hud-z); display:flex; align-items:center; gap:10px; padding:10px 12px; margin:8px; border-radius:14px; background: rgba(15,20,30,.55); backdrop-filter: blur(10px); }
.hc__left{ display:flex; align-items:center; gap:8px; }
.hc__dot{ width:10px; height:10px; border-radius:50%; background:#27d36b; box-shadow:0 0 10px #27d36b; }
.hc__title{ font-weight:700; letter-spacing:.2px; font-size: clamp(14px, 2.8vw, 16px); }
.hc__spacer{ flex:1; }
.hc__pill{ font-size:12px; opacity:.85; padding:6px 10px; border-radius:999px; background: rgba(255,255,255,.08); }
.chatdock{ position: sticky; bottom: 0; z-index: var(--chat-z); display:flex; align-items:center; gap:8px; padding: 10px 10px calc(10px + var(--safe-bottom)); margin: 8px; border-radius: 16px; background: rgba(20,25,35,.72); backdrop-filter: blur(12px); border: 1px solid rgba(255,255,255,.06); }
.chatdock__field{ flex:1; min-height:42px; border:none; outline:0; border-radius:12px; padding:10px 12px; background: rgba(255,255,255,.08); color:#fff; font: 16px system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }
.chatdock__send{ min-width:46px; min-height:42px; border:none; border-radius:12px; font-weight:700; color:#fff; background:#2e6fff; }
.hologram { z-index: var(--sphere-z); pointer-events: none; }
.debug-monitor { z-index: var(--debug-z); }
@media (max-width: 480px){ .hc{ padding: 8px 10px; margin: 6px; } .chatdock{ margin: 6px; } }
```

---

## client/lib/useViewportVh.ts
```ts
import { useEffect } from 'react';
export function useViewportVh() {
  useEffect(() => {
    const set = () => {
      const vh = window.visualViewport ? window.visualViewport.height : window.innerHeight;
      document.documentElement.style.setProperty('--vhpx', `${vh}px`);
    };
    set();
    window.addEventListener('resize', set);
    window.visualViewport?.addEventListener('resize', set);
    return () => {
      window.removeEventListener('resize', set);
      window.visualViewport?.removeEventListener?.('resize', set);
    };
  }, []);
}
```

---

## App.tsx (example wiring)
```tsx
import React from 'react';
import HeaderCompact from '@/components/HeaderCompact';
import ChatInputBar from '@/components/ChatInputBar';
import { AudioUnlock } from '@/components/AudioUnlock';
import { useViewportVh } from '@/lib/useViewportVh';
import { startAlwaysListen } from '@/voice/alwaysListen';
import { DebugBus } from '@/debug/DebugBus';
import '@/styles/layout.css';

export default function App(){
  useViewportVh();
  React.useEffect(() => {
    DebugBus.defineFlags(['STT','TTS','Gate','Orch']);
    startAlwaysListen({ enabled: true, wakeWord: 'lolo' });
  }, []);

  const send = async (text:string) => {
    const { sendToLLM } = await import('@/llm/orchestrator');
    const { speak } = await import('@/voice/tts');
    const reply = await sendToLLM(text);
    await speak(reply);
  };

  return (
    <div className="app">
      <HeaderCompact />
      <div className="hologram">{/* sphere */}</div>
      <div className="debug-monitor">{/* monitor */}</div>
      {/* chat timeline */}
      <ChatInputBar onSend={send} />
      <AudioUnlock />
    </div>
  );
}
```
