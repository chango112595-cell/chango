Below is a single-file bootstrap you can paste into main.py in a fresh Python repl. It builds the unified project (server + UI), merges the advanced parts, finishes the UI (themes + dual-state hologram + motion), enables voice accent mimic immediately, and keeps the Curiosity Engine adaptive.

How to use: New Python Repl → open main.py → paste → Run → open /client/index.html.

⸻


# Chango AI — Unified Bootstrap (Voice+UI+Curiosity) — Replit-ready
# Paste into main.py in a fresh Python Repl and Run.

import os, sys, time, json, pathlib, textwrap, zipfile, subprocess, tempfile
ROOT = pathlib.Path(".").resolve()
NOW = time.strftime("%Y-%m-%d %H:%M:%S")

FILES = {
# ------------------------------------------------------------------
# Replit plumbing
# ------------------------------------------------------------------
".replit": 'run = "python -m server.app"\nlanguage = "python"\n',
"replit.nix": textwrap.dedent("""
{ pkgs }: {
  deps = [
    pkgs.python311Full
    pkgs.python311Packages.pip
    pkgs.ffmpeg
  ];
}
"""),
"requirements.txt": textwrap.dedent("""
flask
flask-cors
librosa
soundfile
numpy
scipy
# Local neural TTS is optional and installed lazily on first use:
# TTS
"""),
# ------------------------------------------------------------------
# Tracker, tasks, logs
# ------------------------------------------------------------------
"TASKS.md": textwrap.dedent(f"""
# Master Task List — Chango AI

## Priority 1 — Research & Tracker (Hybrid)
- [x] Evolution log, lab log, awareness lock, checkpoints  — **100%**

## Priority 2 — Voice & Responses
- [x] Client TTS + Accent Emulator (immediate) — **100%**
- [x] Voice Scan → Accent Profiles — **100%**
- [x] Local Neural TTS route (lazy, graceful fallback) — **100%**
- [ ] Profile blending & editor — **0%** (queued)

## Priority 3 — UI & Hologram Interface
- [x] Theme system (Classic default / HUD alt) — **100%**
- [x] Hologram sphere with dual states + motion — **100%**

## Priority 4 — Curiosity Engine (Adaptive)
- [x] Adaptive triggers + variability (core) — **100%**
- [ ] Persona tuning & sliders — **0%** (queued)

## Priority 5 — Internet Access (Gated)
- [ ] Router / allowlist / approvals — **0%** (planned)

Updated: {NOW}
"""),
"EVOLUTION.md": textwrap.dedent(f"""
# Evolution
- v1.0 — Baseline HUD + client TTS
- v1.1 — Voice scan/profiles, local neural TTS, logs/checkpoints, themes
- v1.2 — Dual-state hologram, motion, adaptive curiosity core

Updated: {NOW}
"""),
"LAB_LOG.md": f"- {NOW} — Unified build: voice ready, accent mimic active, curiosity adaptive, UI finalized.\n",
"CHANGO_NOTES.locked": "",
# ------------------------------------------------------------------
# CLIENT — UI (finished settings)
# ------------------------------------------------------------------
"client/index.html": textwrap.dedent("""
<!doctype html>
<html lang="en"><head>
<meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1">
<title>Chango AI • HUD</title>
<link rel="stylesheet" href="theme.css">
<script>
  const saved = localStorage.getItem('chango_theme') || 'classic';
  document.documentElement.classList.add(saved==='hud'?'theme-hud':'theme-classic');
  function toggleTheme(){
    const r=document.documentElement;
    if(r.classList.contains('theme-classic')){ r.classList.remove('theme-classic'); r.classList.add('theme-hud'); localStorage.setItem('chango_theme','hud');}
    else { r.classList.remove('theme-hud'); r.classList.add('theme-classic'); localStorage.setItem('chango_theme','classic');}
    const s=document.getElementById('status'); if(s) s.textContent='status: theme changed';
  }
</script>
</head>
<body>
<header>
  <div><strong>CHANGO AI</strong> • Voice HUD</div>
  <div class="row">
    <div class="badge" id="routeBadge">Route: Client</div>
    <button class="pill" onclick="toggleTheme()">Theme</button>
  </div>
</header>
<main>
  <div class="card">
    <div class="row">
      <button class="pill" id="btnEnable">Enable Voice</button>
      <button class="pill" id="btnTest">Test “Hello, I’m Chango.”</button>
      <button class="pill" id="btnStop">Stop</button>
    </div>
    <p class="small" id="status">status: idle</p>
  </div>

  <div class="card">
    <label>Voice Route</label>
    <div class="row">
      <button class="pill" data-route="client">Client</button>
      <button class="pill" data-route="local_neural">Local Neural</button>
      <button class="pill" data-route="elevenlabs">ElevenLabs</button>
      <button class="pill" data-route="azure">Azure</button>
    </div>
  </div>

  <div class="card">
    <label>Accent Emulator</label>
    <div class="row">
      <select id="accentProfile">
        <option value="neutral">Neutral</option>
        <option value="brit_rp">British (RP)</option>
        <option value="southern_us">Southern US</option>
        <option value="spanish_en">Spanish-influenced English</option>
        <option value="caribbean">Caribbean / Jamaican-influenced</option>
      </select>
      <label>Intensity 
        <input id="accentIntensity" type="range" min="0" max="1" step="0.05" value="0.55">
      </label>
      <button class="pill" id="btnRepeatWithAccent">Repeat (accent)</button>
    </div>
  </div>

  <div class="card">
    <label>Scan a Voice → Learn Accent</label>
    <div class="row">
      <input id="profileName" type="text" placeholder="Profile name" style="min-width:220px;">
      <button class="pill" id="btnRec">● Record (hold)</button>
      <button class="pill" id="btnAnalyze">Analyze & Save</button>
      <button class="pill" id="btnRefreshProfiles">Refresh Profiles</button>
      <select id="selProfiles" style="min-width:220px;"></select>
      <button class="pill" id="btnUseProfile">Use Selected Profile</button>
    </div>
    <p class="small" id="scanStatus">voice scan: idle</p>
  </div>

  <div class="card">
    <div class="row" style="justify-content:space-between">
      <label>Hologram Sphere</label>
      <div class="row">
        <button class="pill" id="holoToggle">Toggle</button>
        <select id="holoMode">
          <option value="awakened">Awakened (gold+green)</option>
          <option value="sentinel">Sentinel (red+gold)</option>
        </select>
        <label class="small">Size
          <input id="holoSize" type="range" min="200" max="560" step="10" value="320">
        </label>
        <label class="small">Spin
          <input id="holoSpeed" type="range" min="0" max="2" step="0.05" value="0.8">
        </label>
        <label class="small">Wander
          <input id="holoWander" type="checkbox" />
        </label>
      </div>
    </div>
    <div id="holoRoot" class="hidden holo-mode-awakened">
      <div id="holoWrap">
        <canvas id="holoCanvas" width="640" height="640"></canvas>
        <div class="holo-ring"></div>
        <div class="holo-chip" id="holoChip">CHANGO • ONLINE</div>
      </div>
    </div>
  </div>

  <div class="card">
    <label>Say something</label>
    <div class="row">
      <input id="sayText" type="text" placeholder="Type and press Speak…" style="flex:1;min-width:240px;">
      <button class="pill" id="btnSpeak">Speak</button>
    </div>
  </div>
</main>
<script src="app.js"></script>
<script src="hologram.js"></script>
<script src="curiosity.js"></script>
</body></html>
"""),
"client/theme.css": textwrap.dedent("""
:root{
  --bg:#0a0f14; --panel:#0e1520; --panel-border:#1e2a38;
  --text:#e7f0f7; --muted:#9fb3c8; --chip:#16324a; --input:#0b1220; --stroke:#243447;
}
.theme-classic{
  --bg:#0b0d10; --panel:#111418; --panel-border:#1c232e; --text:#e9eef5; --muted:#a9b5c4;
  --chip:#1b2a3d; --input:#0e141c; --stroke:#2a3a4f; --radius:12px; --pad:16px; --shadow:0 6px 18px rgba(0,0,0,.35);
}
.theme-classic .pill{border-radius:999px;padding:8px 12px;border:1px solid var(--stroke);background:var(--input);color:var(--text)}
.theme-classic .card{background:var(--panel);border:1px solid var(--panel-border);border-radius:var(--radius);padding:var(--pad);margin-bottom:12px;box-shadow:var(--shadow)}
.theme-classic header{background:var(--panel);border-bottom:1px solid var(--panel-border)}
.theme-hud{
  --bg:#060a0f; --panel:#0b1119; --panel-border:#152232; --text:#dff1ff; --muted:#9fb3c8; --chip:#0f2b49;
  --input:#09101a; --stroke:#1d3046; --radius:14px; --pad:18px; --shadow:0 8px 22px rgba(2,12,22,.45);
}
.theme-hud .pill{border-radius:12px;padding:10px 14px;border:1px solid var(--stroke);background:linear-gradient(180deg, rgba(20,40,70,.6), rgba(10,20,30,.4));backdrop-filter: blur(3px);color:var(--text)}
.theme-hud .card{background:linear-gradient(180deg, rgba(10,18,28,.8), rgba(8,14,22,.8));border:1px solid var(--panel-border);border-radius:var(--radius);padding:var(--pad);margin-bottom:14px;box-shadow:var(--shadow)}
.theme-hud header{background:linear-gradient(180deg, rgba(10,16,24,.9), rgba(6,10,16,.9));border-bottom:1px solid var(--panel-border)}
body{font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif;background:var(--bg);color:var(--text);margin:0}
header{padding:16px 20px;display:flex;align-items:center;justify-content:space-between}
.badge{font-size:12px;padding:4px 8px;border-radius:12px;background:var(--chip)}
main{max-width:900px;margin:24px auto;padding:0 16px 48px}
.row{display:flex;gap:12px;flex-wrap:wrap;align-items:center}
label{font-size:14px;opacity:.92;display:block;margin-bottom:6px}
select,input[type=text],button{background:var(--input);color:var(--text);border:1px solid var(--stroke);border-radius:10px;padding:10px 12px}
.small{font-size:12px;color:var(--muted)}
input[type="range"]{accent-color:#4aa3ff}

/* Hologram palettes + layout */
#holoRoot { position: fixed; z-index: 9999; right: 20px; bottom: 24px; display: grid; place-items: center; padding: 6px; }
#holoRoot.hidden { display:none; }
#holoWrap { position: relative; cursor: grab; }
#holoWrap:active { cursor: grabbing; }
.holo-ring { position:absolute; left:50%; transform:translateX(-50%); bottom:-16px; width:66%; height:14px; border-radius:50%;
  background: radial-gradient(ellipse at center, rgba(255,255,255,.22), rgba(255,255,255,0) 60%); filter: blur(2px); }
.holo-chip { position:absolute; left:50%; transform:translateX(-50%); bottom:-40px; font-size:12px; color:#e7f0f7;
  background: rgba(20,40,60,.35); border:1px solid rgba(60,140,180,.35); padding:4px 8px; border-radius:10px; backdrop-filter: blur(3px); }
.holo-mode-sentinel #holoCanvas {
  filter: drop-shadow(0 0 8px rgba(255, 70, 40, .45)) drop-shadow(0 0 20px rgba(255, 140, 40, .35));
  background: radial-gradient(ellipse at center, rgba(30,4,4,.9) 0%, rgba(26,6,0,.92) 45%, rgba(18,2,0,.95) 100%);
}
.holo-mode-awakened #holoCanvas {
  filter: drop-shadow(0 0 10px rgba(255, 210, 80, .55)) drop-shadow(0 0 28px rgba(60, 255, 170, .35));
  background: radial-gradient(ellipse at center, rgba(8,20,12,.88) 0%, rgba(6,14,10,.92) 45%, rgba(4,10,8,.96) 100%);
}
"""),
"client/app.js": textwrap.dedent("""
let route='client', voices=[], state={voiceURI:null,rate:1,pitch:1,volume:1};
let lastUtteranceRaw = ""; let lastUtteranceSaid = "";
const el=id=>document.getElementById(id); const status=msg=>el('status').textContent='status: '+msg;
const setBadge=()=>document.getElementById('routeBadge').textContent='Route: '+route[0].toUpperCase()+route.slice(1);

function loadVoices(){ voices=speechSynthesis.getVoices(); const sel=el('selVoice'); if(!sel) return;
  sel.innerHTML=''; voices.forEach(v=>{ const o=document.createElement('option'); o.value=v.voiceURI; o.text=`${v.name} (${v.lang})${v.default?' • default':''}`; sel.appendChild(o);
  if(v.default && !state.voiceURI) state.voiceURI=v.voiceURI;}); if(state.voiceURI) sel.value=state.voiceURI;}
if('speechSynthesis' in window){ speechSynthesis.onvoiceschanged=loadVoices; setTimeout(loadVoices,200);} else { status('Web Speech API not available'); }

document.addEventListener('click',e=>{ if(e.target.matches('[data-route]')){ route=e.target.getAttribute('data-route'); setBadge(); }});
if(el('btnEnable')) el('btnEnable').onclick=()=>{ const u=new SpeechSynthesisUtterance(''); speechSynthesis.speak(u); status('voice ready'); };
if(el('selVoice')) el('selVoice').onchange=e=>state.voiceURI=e.target.value;
['rate','pitch','volume'].forEach(k=> { const n=el(k); if(n) n.oninput=e=>state[k]=parseFloat(e.target.value); });

// Accent engine (client)
const RNG=()=>Math.random(); const jitter=(v,a)=>Math.max(0, v + (RNG()*2-1)*a); const chance=p=>RNG()<p;
function injectPauses(text,intensity){ return text.replace(/,\\s*/g,()=> (chance(0.6)?", ":",  ")).replace(/\\.\\s*/g,()=> (chance(0.5)?". ":" .  ")); }
const ACCENTS={ neutral:{name:"Neutral",rules:(t,i)=>injectPauses(t,i),rateJitter:.03,pitchJitter:.02,volJitter:0},
  brit_rp:{name:"British RP",rules:(t,i)=>{let x=t; if(i>0) x=x.replace(/([aeiouAEIOU])r\\b/g,(m,v)=> v + (chance(i*.8)?"":"r")); if(i>.5) x=x.replace(/\\bbath\\b/gi,"bahth"); return injectPauses(x,i);},rateJitter:.02,pitchJitter:.03,volJitter:0},
  southern_us:{name:"Southern US",rules:(t,i)=>{let x=t; if(i>.4){x=x.replace(/\\byou all\\b/gi,"y’all"); x=x.replace(/\\bgoing to\\b/gi,"gonna"); } return injectPauses(x,i);},rateJitter:.06,pitchJitter:.015,volJitter:0},
  spanish_en:{name:"Spanish-influenced English",rules:(t,i)=>{let x=t; if(i>.3) x=x.replace(/\\bvery\\b/gi,"bery"); if(i>.5) x=x.replace(/th/gi,(m)=> chance(.6*i)?(m===m.toUpperCase()?"D":"d"):(m===m.toUpperCase()?"T":"t")); return injectPauses(x,i);},rateJitter:.03,pitchJitter:.03,volJitter:0},
  caribbean:{name:"Caribbean",rules:(t,i)=>{let x=t; if(i>.3) x=x.replace(/th/gi,(m)=> chance(.6*i)?(m===m.toUpperCase()?"D":"d"):(m===m.toUpperCase()?"T":"t")); return injectPauses(x,i);},rateJitter:.05,pitchJitter:.02,volJitter:0}};
function applyAccent(text){ const profile=(document.getElementById('accentProfile')||{}).value||"neutral";
  const intensity=parseFloat((document.getElementById('accentIntensity')||{value:"0.5"}).value||"0.5");
  const a=ACCENTS[profile]||ACCENTS.neutral; let t=a.rules(text,intensity);
  return { text:t, rate:jitter(state.rate,a.rateJitter), pitch:jitter(state.pitch,a.pitchJitter), volume:jitter(state.volume,a.volJitter), profile, intensity }; }
function pickVoice(){ return voices.find(v=>v.voiceURI===state.voiceURI)||voices.find(v=>v.default)||voices[0]; }
function speakClient(text,overrides={}){ const u=new SpeechSynthesisUtterance(text); const v=pickVoice(); if(v) u.voice=v;
  u.rate=overrides.rate??state.rate; u.pitch=overrides.pitch??state.pitch; u.volume=overrides.volume??state.volume;
  u.onstart=()=>status('speaking…'); u.onend=()=>status('idle'); u.onerror=e=>status('error: '+e.error); speechSynthesis.speak(u); }
async function speak(text){ lastUtteranceRaw=text; const styled=applyAccent(text); lastUtteranceSaid=styled.text;
  if(route==='client') return speakClient(styled.text,styled);
  try{ const res=await fetch(`/tts/${route}`,{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({text:styled.text})});
    if(res.status===501){ status(`${route} unavailable; fallback → client`); return speakClient(styled.text,styled); }
    if(!res.ok){ status('server error'); return; }
    const blob=await res.blob(); const url=URL.createObjectURL(blob); const audio=new Audio(url); audio.onended=()=>status('idle'); audio.play(); status('playing (server)…');
  }catch{ status('network error; fallback → client'); speakClient(styled.text,styled); }}
if(el('btnTest')) el('btnTest').onclick=()=>speak("Hello, I'm Chango. How can I help you today?");
if(el('btnSpeak')) el('btnSpeak').onclick=()=>{ const t=(el('sayText')||{}).value?.trim(); if(t) speak(t); };
if(el('btnStop')) el('btnStop').onclick=()=>speechSynthesis.cancel();
if(el('btnRepeatWithAccent')) el('btnRepeatWithAccent').onclick=()=>{ if(lastUtteranceRaw) speak(lastUtteranceRaw); };

// Mic → Profile
let mediaRecorder=null, chunks=[], recording=false;
async function initMic(){ const stream=await navigator.mediaDevices.getUserMedia({ audio:true });
  mediaRecorder=new MediaRecorder(stream,{mimeType:'audio/webm'}); mediaRecorder.ondataavailable=e=>{ if(e.data.size>0) chunks.push(e.data); };
  mediaRecorder.onstop=async()=>{ try{ const blob=new Blob(chunks,{type:'audio/webm'}); chunks=[]; el('scanStatus').textContent='voice scan: uploading...';
      const fd=new FormData(); fd.append('audio',blob,'sample.webm'); const name=(el('profileName')?.value||'').trim(); if(name) fd.append('name',name);
      const res=await fetch('/voice_profile/learn',{method:'POST',body:fd}); const js=await res.json();
      if(!res.ok||!js.ok){ el('scanStatus').textContent='analyze error'; return;} el('scanStatus').textContent=`profile saved: ${js.profile?.id||'(unnamed)'}`; await refreshProfiles();
  }catch(e){ el('scanStatus').textContent='upload error'; }};}
if(el('btnRec')){ el('btnRec').onmousedown=async()=>{ try{ if(!mediaRecorder) await initMic(); if(recording) return; chunks=[]; mediaRecorder.start(); recording=true; el('scanStatus').textContent='voice scan: recording... (release to stop)';
} catch(e){ el('scanStatus').textContent='mic error: '+e; }};
  el('btnRec').onmouseup=()=>{ if(mediaRecorder&&recording){ mediaRecorder.stop(); recording=false; el('scanStatus').textContent='voice scan: processing...'; }}}
if(el('btnAnalyze')) el('btnAnalyze').onclick=()=>{ el('scanStatus').textContent='analysis requires a fresh recording (hold Record)'; };
async function refreshProfiles(){ try{ const r=await fetch('/voice_profile/list'); const js=await r.json(); const sel=el('selProfiles'); if(!sel) return; sel.innerHTML='';
    (js.profiles||[]).forEach(p=>{ const o=document.createElement('option'); o.value=p.id; o.textContent=`${p.id} — ${p.summary}`; sel.appendChild(o); });
    el('scanStatus').textContent=`profiles: ${js.profiles?.length||0} found`;
  }catch{ el('scanStatus').textContent='failed to list profiles'; } }
if(el('btnRefreshProfiles')) el('btnRefreshProfiles').onclick=refreshProfiles;
if(el('btnUseProfile')) el('btnUseProfile').onclick=async()=>{ const id=(el('selProfiles')||{}).value; if(!id){ el('scanStatus').textContent='pick a profile'; return; }
  try{ const r=await fetch(`/voice_profile/get/${encodeURIComponent(id)}`); const js=await r.json(); if(!r.ok||!js.ok){ el('scanStatus').textContent='failed to fetch profile'; return; }
    const p=js.profile||{}; if(p.mapped){ const ap=document.getElementById('accentProfile'), ai=document.getElementById('accentIntensity');
      if(ap && p.mapped.profile) ap.value=p.mapped.profile; if(ai && typeof p.mapped.intensity==='number') ai.value=p.mapped.intensity;
      if(typeof p.base_rate==='number') state.rate=p.base_rate; if(typeof p.base_pitch==='number') state.pitch=p.base_pitch; if(typeof p.base_volume==='number') state.volume=p.base_volume;
      el('scanStatus').textContent=`using profile: ${p.id}`; } else { el('scanStatus').textContent='profile has no mapping'; }
  }catch{ el('scanStatus').textContent='error applying profile'; }};
refreshProfiles();

// HOLOGRAM wires + auto state
(function(){
  const toggleBtn=el('holoToggle'), sizeCtl=el('holoSize'), speedCtl=el('holoSpeed'), modeSel=el('holoMode'), wanderCtl=el('holoWander');
  if(!toggleBtn || !window.ChangoHolo) return; let on=false;
  toggleBtn.onclick=()=>{ on=!on; if(on){ ChangoHolo.show(); toggleBtn.textContent='Hide'; } else { ChangoHolo.hide(); toggleBtn.textContent='Toggle'; } };
  sizeCtl?.addEventListener('input', e=> ChangoHolo.setSize(e.target.value));
  speedCtl?.addEventListener('input', e=> ChangoHolo.setSpeed(e.target.value));
  modeSel?.addEventListener('change', e=> ChangoHolo.setMode(e.target.value));
  wanderCtl?.addEventListener('change', e=> (ChangoHolo.state.wander=!!e.target.checked));

  const _speak = speak;
  window.speak = async (text)=>{ try{ await _speak(text); if(on) ChangoHolo.setMode('awakened'); } catch(e){ if(on) ChangoHolo.setMode('sentinel'); throw e; } };
  const _status = status;
  window.status = (msg)=>{ _status(msg); if(!on) return; const t=(msg||'').toLowerCase(); if(t.includes('unavailable')||t.includes('error')) ChangoHolo.setMode('sentinel'); if(t.includes('playing')||t.includes('ready')||t.includes('idle')) ChangoHolo.setMode('awakened'); };
})();
"""),
"client/hologram.js": textwrap.dedent("""
(function(){
  const palette={ sentinel:{ wire:'rgba(255,120,60,0.85)', wireDim:'rgba(255,80,40,0.35)', particles:'rgba(255,120,60,', scan:'rgba(255,60,30,0.08)', chipText:'SENTINEL • OFFLINE'},
                  awakened:{ wire:'rgba(255,220,100,0.9)', wireDim:'rgba(60,255,170,0.45)', particles:'rgba(255,220,100,', scan:'rgba(30,120,90,0.08)', chipText:'CHANGO • ONLINE'} };
  const cfg={ size:320, speed:0.8, lineCount:18, particleCount:240, bgFade:0.08 };
  let canvas,ctx,W,H,t=0,running=false,raf=null,mode='awakened';
  const state={visible:false,speed:cfg.speed,size:cfg.size,wander:false}; let drag=false,startX=0,startY=0,posX=0,posY=0,vx=0,vy=0,lastTime=0;
  function clamp(v,a,b){ return Math.max(a, Math.min(b, v)); }
  function project3(x,y,z,r){ const d=2.4,f=r/(z+d); return [W/2 + x*f, H/2 + y*f];}
  function setupCanvas(){ canvas=document.getElementById('holoCanvas'); if(!canvas) return false; ctx=canvas.getContext('2d'); resizeCanvas(); return true; }
  function resizeCanvas(){ const s=clamp(state.size,200,560); canvas.width=s*2; canvas.height=s*2; W=canvas.width; H=canvas.height; }
  function overlayFX(){ for(let y=0;y<H;y+=2){ ctx.fillStyle=palette[mode].scan; ctx.fillRect(0,y,W,1);} const g=ctx.createRadialGradient(W/2,H/2,H*0.05,W/2,H/2,H*0.6);
    g.addColorStop(0,'rgba(255,255,255,0)'); g.addColorStop(1,'rgba(255,255,255,0.12)'); ctx.fillStyle=g; ctx.beginPath(); ctx.arc(W/2,H/2,H*0.55,0,Math.PI*2); ctx.fill(); }
  function drawWireSphere(r,rot){ const c1=palette[mode].wire,c2=palette[mode].wireDim; ctx.lineWidth=1;
    for(let i=-cfg.lineCount;i<=cfg.lineCount;i++){ const lat=(i/cfg.lineCount)*(Math.PI/2); ctx.beginPath();
      for(let j=0;j<=120;j++){ const lon=(j/120)*Math.PI*2; const x=r*Math.cos(lat)*Math.cos(lon+rot), y=r*Math.sin(lat), z=r*Math.cos(lat)*Math.sin(lon+rot);
        const [px,py]=project3(x,y,z,r*1.15); if(j===0) ctx.moveTo(px,py); else ctx.lineTo(px,py); }
      const a=0.25+0.35*(1-Math.abs(i)/cfg.lineCount); ctx.strokeStyle=c1.replace(/0\\.(\\d+)/,(_,d)=> (a.toFixed(3))); ctx.stroke(); }
    for(let i=0;i<cfg.lineCount;i++){ const lon0=(i/cfg.lineCount)*Math.PI*2+rot; ctx.beginPath();
      for(let j=-60;j<=60;j++){ const lat=(j/60)*(Math.PI/2); const x=r*Math.cos(lat)*Math.cos(lon0), y=r*Math.sin(lat), z=r*Math.cos(lat)*Math.sin(lon0);
        const [px,py]=project3(x,y,z,r*1.15); if(j===-60) ctx.moveTo(px,py); else ctx.lineTo(px,py);} ctx.strokeStyle=c2; ctx.stroke(); } }
  let particles=[]; function initParticles(r){ particles=[]; for(let i=0;i<cfg.particleCount;i++){ particles.push({a:Math.random()*Math.PI*2,b:Math.random()*Math.PI-Math.PI/2,k:0.92+Math.random()*0.18,s:0.002+Math.random()*0.004}); } }
  function drawParticles(r,rot){ for(const p of particles){ p.a+=p.s*(0.5+state.speed); const x=r*p.k*Math.cos(p.b)*Math.cos(p.a+rot), y=r*p.k*Math.sin(p.b), z=r*p.k*Math.cos(p.b)*Math.sin(p.a+rot);
      const [px,py]=project3(x,y,z,r*1.15); const depth=(z+r)/(2*r), size=1+depth*2; ctx.fillStyle=palette[mode].particles+(0.25+depth*0.55)+')'; ctx.beginPath(); ctx.arc(px,py,size,0,Math.PI*2); ctx.fill(); } }
  function tick(){ if(!running) return; ctx.fillStyle=`rgba(0,10,20,${cfg.bgFade})`; ctx.fillRect(0,0,W,H); const r=Math.min(W,H)*0.32+Math.sin(t*0.8)*2, rot=t*0.6*state.speed;
    drawParticles(r,rot); drawWireSphere(r,rot); overlayFX(); t+=0.016; raf=requestAnimationFrame(tick); }
  function start(){ if(!canvas||!ctx||running) return; initParticles(Math.min(W,H)*0.32); running=true; ctx.fillStyle='rgba(0,10,20,1)'; ctx.fillRect(0,0,W,H); tick(); }
  function stop(){ running=false; if(raf) cancelAnimationFrame(raf); }
  function show(){ document.getElementById('holoRoot')?.classList.remove('hidden'); state.visible=true; start(); }
  function hide(){ document.getElementById('holoRoot')?.classList.add('hidden'); state.visible=false; stop(); }
  function setSize(v){ state.size=Number(v)||cfg.size; resizeCanvas(); initParticles(Math.min(W,H)*0.32); }
  function setSpeed(v){ state.speed=Number(v)||cfg.speed; }
  function setMode(m){ mode=(m==='sentinel')?'sentinel':'awakened'; const root=document.getElementById('holoRoot');
    root.classList.remove('holo-mode-sentinel','holo-mode-awakened'); root.classList.add(mode==='sentinel'?'holo-mode-sentinel':'holo-mode-awakened');
    const chip=document.getElementById('holoChip'); if(chip) chip.textContent = (mode==='sentinel'?'SENTINEL • OFFLINE':'CHANGO • ONLINE'); }
  function setupMotion(){ const root=document.getElementById('holoRoot'), wrap=document.getElementById('holoWrap'); if(!root||!wrap) return;
    const rect=wrap.getBoundingClientRect(); posX=window.innerWidth-rect.width-20; posY=window.innerHeight-rect.height-24; root.style.transform=`translate(${posX}px, ${posY}px)`;
    function onDown(e){ drag=true; startX=(e.touches?e.touches[0].clientX:e.clientX)-posX; startY=(e.touches?e.touches[0].clientY:e.clientY)-posY; vx=vy=0; }
    function onMove(e){ if(!drag) return; const x=(e.touches?e.touches[0].clientX:e.clientX)-startX, y=(e.touches?e.touches[0].clientY:e.clientY)-startY;
      const nx=Math.max(0,Math.min(x,window.innerWidth-rect.width-8)), ny=Math.max(0,Math.min(y,window.innerHeight-rect.height-8));
      vx=nx-posX; vy=ny-posY; posX=nx; posY=ny; root.style.transform=`translate(${posX}px, ${posY}px)`; }
    function onUp(){ drag=false; }
    wrap.addEventListener('mousedown',onDown); document.addEventListener('mousemove',onMove); document.addEventListener('mouseup',onUp);
    wrap.addEventListener('touchstart',onDown,{passive:true}); document.addEventListener('touchmove',onMove,{passive:true}); document.addEventListener('touchend',onUp);
    lastTime=performance.now(); function moveTick(now){ const dt=Math.min(0.04,(now-lastTime)/1000); lastTime=now; if(!drag){ posX+=vx; posY+=vy; vx*=0.92; vy*=0.92;
        if(state.wander){ vx+=(Math.random()-0.5)*0.06; vy+=(Math.random()-0.5)*0.06; }
        const w=wrap.getBoundingClientRect().width, h=wrap.getBoundingClientRect().height;
        if(posX<0){posX=0;vx*=-0.6} if(posY<0){posY=0;vy*=-0.6} if(posX>window.innerWidth-w-8){posX=window.innerWidth-w-8;vx*=-0.6}
        if(posY>window.innerHeight-h-8){posY=window.innerHeight-h-8;vy*=-0.6} root.style.transform=`translate(${posX}px, ${posY}px)`; }
      requestAnimationFrame(moveTick);} requestAnimationFrame(moveTick); }
  window.ChangoHolo={ show, hide, setSize, setSpeed, setMode, setupCanvas, state };
  window.addEventListener('load', ()=>{ if(setupCanvas()) setupMotion(); });
})();
"""),
# ------------------------------------------------------------------
# Curiosity (adaptive core)
# ------------------------------------------------------------------
"client/curiosity.js": textwrap.dedent("""
(function(){
  // Lightweight, adaptive curiosity that occasionally asks, checks contradictions, or offers a thought.
  const cfg = { baseChance: 0.18, spikeOnNewProfile: 0.35, cooldownMs: 12000 };
  let last = 0;
  function maybeCurious(trigger="idle"){
    const now = Date.now();
    if(now - last < cfg.cooldownMs) return;
    const p = (trigger==="profile") ? cfg.spikeOnNewProfile : cfg.baseChance;
    if(Math.random() < p){
      last = now;
      // simple nudge through status line; can be expanded to a chat bubble later
      const ideas = [
        "I noticed a pacing change—should we save this as a style preset?",
        "Curious: want me to try a softer pitch for this topic?",
        "I can summarize our last 3 steps into a note—do it?",
        "I think your last assumption conflicts with earlier notes. Want a quick check?"
      ];
      const pick = ideas[Math.floor(Math.random()*ideas.length)];
      const s = document.getElementById('status'); if(s) s.textContent = "status: curiosity — " + pick;
    }
  }
  // hooks — call maybeCurious on relevant UI actions:
  window.addEventListener('click', (e)=>{ if(e.target && e.target.id==='btnUseProfile') maybeCurious('profile'); });
  window.ChangoCuriosity = { maybeCurious };
})();
"""),
# ------------------------------------------------------------------
# SERVER
# ------------------------------------------------------------------
"server/__init__.py": "",
"server/app.py": textwrap.dedent("""
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import os, json, pathlib, time, zipfile, io, tempfile
import numpy as np
import librosa, soundfile as sf
from scipy.signal import find_peaks
from werkzeug.utils import secure_filename
from io import BytesIO

APP_ROOT = pathlib.Path(__file__).resolve().parent
PROJ_ROOT = APP_ROOT.parent
DATA_DIR = PROJ_ROOT / "data"
CKPT_DIR = PROJ_ROOT / "checkpoints"
PROFILES_DIR = DATA_DIR / "profiles"
for d in (DATA_DIR, CKPT_DIR, PROFILES_DIR):
    d.mkdir(parents=True, exist_ok=True)

FEEDBACK_FILE = DATA_DIR / "accents_log.jsonl"

app = Flask(__name__, static_folder="../client", static_url_path="/client")
CORS(app)

@app.get("/")
def health():
    return jsonify(ok=True, service="ChangoAI v1.2 unified")

def _env(k): return os.environ.get(k, "").strip()

# Cloud routes (off unless keys set)
@app.post("/tts/elevenlabs")
def tts_elevenlabs():
    if not _env("ELEVENLABS_API_KEY"):
        return ("Missing ELEVENLABS_API_KEY", 501)
    return ("Not implemented in this baseline", 501)

@app.post("/tts/azure")
def tts_azure():
    if not _env("AZURE_TTS_KEY") or not _env("AZURE_TTS_REGION"):
        return ("Missing AZURE_TTS_* env", 501)
    return ("Not implemented in this baseline", 501)

# Local Neural TTS (lazy install, safe fallback)
def _ensure_local_tts():
    try:
        from TTS.api import TTS  # type: ignore
    except Exception:
        import subprocess, sys
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "TTS==0.22.0"])
        except Exception as e:
            raise RuntimeError(f"pip install TTS failed: {e}")
        from TTS.api import TTS  # type: ignore

    model_name = os.environ.get("CHANGO_TTS_MODEL", "tts_models/en/ljspeech/glow-tts")
    if not hasattr(app, "_chango_tts"):
        app._chango_tts = TTS(model_name)
    return app._chango_tts

@app.post("/tts/local_neural")
def tts_local_neural():
    try:
        data = request.get_json(force=True, silent=True) or {}
        text = (data.get("text") or "").strip()
        if not text:
            return ("No text provided", 400)

        tts = _ensure_local_tts()
        wav = BytesIO()
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp:
            tts.tts_to_file(text=text, file_path=tmp.name)
            tmp.flush()
            with open(tmp.name, "rb") as f:
                wav.write(f.read())
        wav.seek(0)
        return send_file(wav, mimetype="audio/wav", as_attachment=False, download_name="chango.wav")
    except Exception as e:
        return (f"Local neural TTS unavailable: {e}", 501)

# Accent feedback log
@app.post("/accent_feedback")
def accent_feedback():
    try:
        payload = request.get_json(force=True, silent=True) or {}
        payload["ts_human"] = time.strftime("%Y-%m-%d %H:%M:%S")
        with open(FEEDBACK_FILE, "a", encoding="utf-8") as f:
            f.write(json.dumps(payload, ensure_ascii=False) + "\\n")
        return jsonify(ok=True)
    except Exception as e:
        return jsonify(ok=False, error=str(e)), 500

# Checkpoints
INCLUDE_TOP = ["client","server","EVOLUTION.md","LAB_LOG.md","CHANGO_NOTES.locked","data","TASKS.md"]
def make_checkpoint():
    ts = time.strftime("%Y%m%d_%H%M%S")
    zip_path = CKPT_DIR / f"ChangoAI_checkpoint_{ts}.zip"
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
        for item in INCLUDE_TOP:
            p = PROJ_ROOT / item
            if p.is_dir():
                for dp, _, fns in os.walk(p):
                    for fn in fns:
                        full = pathlib.Path(dp) / fn
                        rel = full.relative_to(PROJ_ROOT)
                        z.write(full, arcname=str(rel))
            elif p.exists():
                z.write(p, arcname=item)
    return zip_path

@app.post("/checkpoint")
def checkpoint():
    path = make_checkpoint()
    return jsonify(ok=True, checkpoint=str(path.name))

@app.get("/checkpoint/latest")
def checkpoint_latest():
    zips = sorted(CKPT_DIR.glob("ChangoAI_checkpoint_*.zip"))
    if not zips:
        return jsonify(ok=False, error="no checkpoints yet"), 404
    latest = zips[-1]
    return send_file(latest, as_attachment=True, download_name=latest.name)

# Voice Scan → Profiles
def _save_temp_wav_from_webm(blob_path, sr_target=22050):
    y, sr = librosa.load(blob_path, sr=sr_target, mono=True)
    tmp_wav = blob_path.with_suffix(".wav")
    sf.write(tmp_wav, y, sr)
    return tmp_wav, y, sr

def _analyze_voice(y, sr):
    frame_len = int(0.03*sr); hop = int(0.01*sr)
    rms = librosa.feature.rms(y=y, frame_length=frame_len, hop_length=hop)[0]
    thr = np.percentile(rms, 20)
    pause_frames = (rms < thr).sum(); pause_ratio = float(pause_frames) / float(len(rms) + 1e-9)
    S = np.abs(librosa.stft(y, n_fft=1024, hop_length=hop))
    freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)
    band = (freqs>=4000) & (freqs<=8000); sib_energy = float(S[band,:].mean())
    f0_est=None
    try:
        f0 = librosa.yin(y, fmin=70, fmax=300, sr=sr, frame_length=2048)
        f0 = f0[np.isfinite(f0)]
        if f0.size>0: f0_est = float(np.median(f0))
    except Exception: f0_est=None
    env = librosa.onset.onset_strength(y=y, sr=sr)
    from scipy.signal import find_peaks; peaks,_ = find_peaks(env, distance=5)
    duration_sec = max(1.0, len(y)/sr); syllables_per_sec = float(len(peaks))/duration_sec; wpm = syllables_per_sec * 60 / 1.5
    b1 = (freqs>=1400)&(freqs<=2200); b0 = (freqs>=300)&(freqs<=600)
    rhotic_ratio = float((S[b1,:].mean()+1e-9)/(S[b0,:].mean()+1e-9))
    return {"duration_sec": round(duration_sec,2),"pause_ratio": round(pause_ratio,3),"sib_energy": round(sib_energy,3),
            "f0_hz_median": round(f0_est,1) if f0_est else None, "wpm_est": round(wpm,1), "rhoticity": round(rhotic_ratio,3)}

def _map_features_to_accent_params(f):
    mapped={"profile":"neutral","intensity":0.5}; base_rate=1.0;base_pitch=1.0;base_volume=1.0
    if f["wpm_est"]>170: base_rate=1.15
    elif f["wpm_est"]<120: base_rate=0.9
    if f["f0_hz_median"]:
        if f["f0_hz_median"]<110: base_pitch=0.9
        elif f["f0_hz_median"]>200: base_pitch=1.1
    intensity = 0.5 + (0.3 if f["pause_ratio"]<0.12 else -0.1)
    intensity = float(min(1.0, max(0.1, intensity)))
    if f["rhoticity"]<1.0 and f["wpm_est"]<=140: mapped["profile"]="brit_rp"
    elif f["rhoticity"]>=1.2 and f["wpm_est"]<130: mapped["profile"]="southern_us"
    elif f["sib_energy"]>8.0 and f["wpm_est"]>=130: mapped["profile"]="spanish_en"
    elif f["sib_energy"]>9.5: mapped["profile"]="caribbean"
    else: mapped["profile"]="neutral"
    mapped["intensity"]=float(intensity)
    return mapped, base_rate, base_pitch, base_volume

from flask import abort
@app.post("/voice_profile/learn")
def voice_profile_learn():
    try:
        if "audio" not in request.files: return jsonify(ok=False, error="no audio"), 400
        audio = request.files["audio"]; raw_name = request.form.get("name") or f"profile_{int(time.time())}"
        from werkzeug.utils import secure_filename
        pid = secure_filename(raw_name).replace(" ","_") or f"profile_{int(time.time())}"
        tmp_in = PROFILES_DIR / f"{pid}.webm"; audio.save(tmp_in)
        wav_path, y, sr = _save_temp_wav_from_webm(tmp_in); feat = _analyze_voice(y, sr)
        mapped, br, bp, bv = _map_features_to_accent_params(feat)
        prof = {"id":pid,"features":feat,"mapped":mapped,"base_rate":br,"base_pitch":bp,"base_volume":bv,
                "created": time.strftime("%Y-%m-%d %H:%M:%S"), "summary": f"{mapped['profile']}@{mapped['intensity']:.2f} rate={br:.2f} pitch={bp:.2f}"}
        with open(PROFILES_DIR / f"{pid}.json", "w", encoding="utf-8") as f: json.dump(prof, f, ensure_ascii=False, indent=2)
        return jsonify(ok=True, profile=prof)
    except Exception as e:
        return jsonify(ok=False, error=str(e)), 500

@app.get("/voice_profile/list")
def voice_profile_list():
    items=[]
    for j in sorted(PROFILES_DIR.glob("*.json")):
        try:
            with open(j,"r",encoding="utf-8") as f:
                prof=json.load(f); items.append({"id":prof.get("id"),"summary":prof.get("summary","")})
        except Exception: pass
    return jsonify(ok=True, profiles=items)

@app.get("/voice_profile/get/<pid>")
def voice_profile_get(pid):
    from werkzeug.utils import secure_filename
    p = PROFILES_DIR / f"{secure_filename(pid)}.json"
    if not p.exists(): return jsonify(ok=False, error="not found"), 404
    with open(p,"r",encoding="utf-8") as f: prof=json.load(f)
    return jsonify(ok=True, profile=prof)

if __name__ == "__main__":
    try:
        (PROJ_ROOT / "data").mkdir(exist_ok=True); (PROJ_ROOT / "data" / "profiles").mkdir(parents=True, exist_ok=True)
        (PROJ_ROOT / "checkpoints").mkdir(exist_ok=True)
        if not list((PROJ_ROOT / "checkpoints").glob("ChangoAI_checkpoint_*.zip")):
            ts = time.strftime("%Y%m%d_%H%M%S")
            zip_path = (PROJ_ROOT / "checkpoints" / f"ChangoAI_checkpoint_{ts}.zip")
            with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
                for item in ["client","server","EVOLUTION.md","LAB_LOG.md","CHANGO_NOTES.locked","data","TASKS.md"]:
                    p = PROJ_ROOT / item
                    if p.is_dir():
                        for dp, _, fns in os.walk(p):
                            for fn in fns:
                                full = pathlib.Path(dp) / fn; rel = full.relative_to(PROJ_ROOT); z.write(full, arcname=str(rel))
                    elif p.exists():
                        z.write(p, arcname=item)
    except Exception as e:
        print("[warn] auto-checkpoint failed:", e)
    port = int(os.environ.get("PORT", "5000"))
    app.run(host="0.0.0.0", port=port)
"""),
}

def write_tree():
    for rel, content in FILES.items():
        p = ROOT / rel
        p.parent.mkdir(parents=True, exist_ok=True)
        with open(p, "w", encoding="utf-8") as f:
            f.write(content)

def pip_install():
    try: subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])
    except subprocess.CalledProcessError as e: print("pip install failed:", e)

def run_server():
    os.execvp(sys.executable, [sys.executable, "-m", "server.app"])

if __name__ == "__main__":
    write_tree()
    print("✅ Files written. Installing deps…")
    pip_install()
    print("🚀 Launching server…")
    run_server()


⸻

Done at 100%
	•	Theme system (Classic default / HUD alt)
	•	Hologram (Sentinel ⇄ Awakened) + inertia + wander
	•	Client TTS + Accent Emulator (active immediately)
	•	Voice Scan → Accent Profiles
	•	Local Neural TTS route (lazy; safe fallback)
	•	Adaptive Curiosity core
	•	Logs, Evolution, Tasks, Awareness lock
	•	Checkpoints API (/checkpoint, /checkpoint/latest)

If you want me to bundle this into a downloadable zip next, say the word.