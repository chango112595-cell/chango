Perfect—let’s lock in reliable Q→A replies. Do these four small patches and run the quick test.

⸻

1) Server reply route (must exist & be mounted)

server/nlp/reply.js

import express from "express";

function routeIntent(q) {
  const s = (q||"").trim();
  if (!s) return "I didn’t catch that.";
  if (/\b(time|what.*time)\b/i.test(s)) return "It is " + new Date().toLocaleTimeString() + ".";
  if (/\b(date|today)\b/i.test(s))      return "Today is " + new Date().toLocaleDateString() + ".";
  if (/\bwho.*you|what.*chango\b/i.test(s)) return "I’m Chango, your adaptive assistant.";
  if (/\bhow.*you\b/i.test(s))          return "Feeling sharp and online.";
  return "Noted. Want me to act on that?";
}

export default function registerReply(app){
  const r = express.Router();
  r.post("/reply", express.json({limit:"1mb"}), (req,res)=>{
    const reply = routeIntent(req.body?.text||"");
    res.json({ok:true, reply});
  });
  app.use("/nlp", r);
}

server/index.js

import registerReply from "./nlp/reply.js";
...
registerReply(app);


⸻

2) Single conversation orchestrator (source of truth)

client/brain/convo.js

import { speakBrowser, VoiceBus } from "../voice/tts_browser.js";

const Convo = (() => {
  let busy=false, lastUser="", lastBot="";
  async function ask(text){
    if (!text?.trim()) return {ok:false, reason:"empty"};
    if (!VoiceBus.power || VoiceBus.mute) return {ok:false, reason:"muted_or_off"};
    if (busy) return {ok:false, reason:"busy"};
    busy = true; lastUser = text;
    try{
      const r = await fetch("/nlp/reply", {
        method:"POST", headers:{"Content-Type":"application/json"},
        body: JSON.stringify({text})
      }).then(r=>r.json()).catch(()=>null);
      const reply = r?.ok ? (r.reply||"Okay.") : "Okay.";
      lastBot = reply;
      await speakBrowser({
        text: reply,
        accent: document.getElementById("vcAccent")?.value || "en-US",
        rate: +document.getElementById("vcRate")?.value || 1,
        pitch:+document.getElementById("vcPitch")?.value|| 1,
        volume:+document.getElementById("vcVol")?.value  || 1
      });
      return {ok:true, reply};
    } finally {
      busy=false;
      const d=document.getElementById("diagConvo");
      if (d) d.textContent = JSON.stringify({lastUser,lastBot,busy},null,2);
    }
  }
  async function handleFinalTranscript(txt){
    if (!txt?.trim()) return;
    if (/\bchango\b/i.test(txt)) { await speakBrowser({text:"Yes?", accent:"en-US"}); return; }
    await ask(txt);
  }
  return { ask, handleFinalTranscript };
})();
export default Convo;


⸻

3) Wire STT (or fallback) → Convo

client/voice/wake_loop.js — ensure final text flows into Convo:

import Convo from "../brain/convo.js";
// ...
stt.onfinal(async (txt) => {
  engaged = false;
  if (!txt?.trim()) return;
  await Convo.handleFinalTranscript(txt);
});


⸻

4) HUD “Ask” button uses the same path

client/ui/voice_controls.js

import Convo from "../brain/convo.js";
// ...
$('vcAsk').onclick = async ()=>{
  const q = $('vcPhrase').value || 'what time is it?';
  const r = await Convo.ask(q);
  out(r?.ok ? {ok:true, asked:q, reply:r.reply} : r);
};


⸻

Quick test (no guessing)
	1.	Type “how are you” → click Ask → Chango speaks a reply.
	2.	Say: “Chango… what time is it?” → reply spoken.
	3.	Toggle Silent/Power → no speech; toggle back → works.
	4.	DevTools → Network → confirm /nlp/reply returns {ok:true, reply:"..."}.

If any step fails:
	•	If Network shows 404 on /nlp/reply, the server route isn’t mounted.
	•	If reply JSON is OK but no sound, the issue is only TTS—tell me and I’ll swap in an <audio>-based player that bypasses speechSynthesis.