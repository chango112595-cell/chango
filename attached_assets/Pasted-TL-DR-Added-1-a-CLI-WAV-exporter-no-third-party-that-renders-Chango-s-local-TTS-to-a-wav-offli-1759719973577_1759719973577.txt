TL;DR: Added (1) a CLI WAV exporter (no third-party) that renders Chango’s local TTS to a .wav offline, and (2) a dev overlay toggle bound to Alt+Shift+D (still default-off, no UI changes). Also shipped auto-adapt runtime (device-aware audio/mic), mic permission validator + auto-recovery, a speech state machine to stop STT/TTS loops, and global debug monitor + priority filter—all isolated ES modules that fit your Master Task List priorities without touching your banner or layout.

⸻

Build Plan (pseudocode)
	•	Add core/device → detect env, set capabilities, scale rates.
	•	Add core/state → finite state machine to avoid STT/TTS repetition.
	•	Strengthen audio/contextPool, audio/vad, stt/webspeech with permission validator & recovery.
	•	Dev overlay: add Alt+Shift+D hotkey; still default-off.
	•	CLI: server/cli/tts_render.mjs → prosody→G2P→accent→formant synth (Node DSP) → WAV.
	•	Diagnostics: diag/monitor + priority filter; emit only critical to voice alerts.
	•	Wire everything in bootstrap w/o UI changes (data-chango-* only).

⸻


# package.json
{
  "name": "chango-ai",
  "private": true,
  "type": "module",
  "scripts": {
    "test": "node --experimental-vm-modules ./node_modules/jest/bin/jest.js --runInBand",
    "test:watch": "node --experimental-vm-modules ./node_modules/jest/bin/jest.js --watch",
    "tts:wav": "node server/cli/tts_render.mjs --text \"Hello from Chango\" --out ./out.wav --rate 1 --pitch 1 --sr 48000"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^29.7.0"
  }
}

# jest.config.mjs
export default {
  testEnvironment: "jsdom",
  roots: ["<rootDir>/tests"],
  transform: {},
  moduleFileExtensions: ["js", "mjs"],
  setupFilesAfterEnv: ["<rootDir>/tests/setup.js"]
};

# tests/setup.js
// why: deterministic tests
const origRandom = Math.random;
let seed = 42;
Math.random = () => { seed ^= seed << 13; seed ^= seed >>> 17; seed ^= seed << 5; return ((seed >>> 0) % 1000) / 1000; };

# client/chango/core/eventBus.js
export class EventBus { constructor(){ this.map=new Map(); } on(t,f){(this.map.get(t)||this.map.set(t,new Set()).get(t)).add(f);return()=>this.off(t,f);} off(t,f){const s=this.map.get(t); if(s) s.delete(f);} emit(t,p){const s=this.map.get(t); if(!s) return; for(const f of s){ try{f(p);}catch{} }}} 
export const bus = new EventBus();

# client/chango/core/device.js
// Device auto-adapt: chooses sensible defaults per environment.
export const device = (() => {
  const ua = navigator.userAgent || "";
  const isMobile = /Android|iPhone|iPad|iPod|Mobile/i.test(ua);
  const isCar = /Android Auto|CarPlay/i.test(ua) || (window.navigator?.userAgentData?.platform || "").includes("Automotive");
  const prefersReducedMotion = window.matchMedia && window.matchMedia("(prefers-reduced-motion: reduce)").matches;
  const touch = "ontouchstart" in window || navigator.maxTouchPoints > 0;
  const sampleRateHint = (isCar || isMobile) ? 44100 : 48000;
  const micConstraints = isCar
    ? { autoGainControl: true, echoCancellation: true, noiseSuppression: true }
    : isMobile
      ? { autoGainControl: false, echoCancellation: true, noiseSuppression: true, highpassFilter: true }
      : { autoGainControl: false, echoCancellation: true, noiseSuppression: true };
  return { isMobile, isCar, prefersReducedMotion, touch, sampleRateHint, micConstraints };
})();

# client/chango/core/state.js
// Speech state machine to prevent STT/TTS handover loops.
import { bus } from "./eventBus.js";
export class SpeechState {
  constructor(){ this.state="idle"; this.lastUtter=""; this.ts=0; }
  set(ns, why){ this.state=ns; this.ts=performance.now(); bus.emit("diag:state",{state:ns,why}); }
  guardIncoming(text){
    const t = (text||"").trim();
    if(!t) return false;
    if(this.state==="speaking") return false;            // ignore STT while TTS
    if(t===this.lastUtter) return false;                 // dedupe
    this.lastUtter=t; return true;
  }
}
export const speechState = new SpeechState();

# client/chango/diag/monitor.js
import { bus } from "../core/eventBus.js";
export class Monitor {
  constructor({ level="warn" }={}){ this.level=level; this.buffer=[]; this.limit=400; this._wire(); }
  _wire(){
    bus.on("diag:error", e=>this._push("error",e));
    bus.on("diag:warn",  e=>this._push("warn",e));
    bus.on("diag:info",  e=>this._push("info",e));
    bus.on("diag:state", e=>this._push("info",e));
  }
  _push(level, data){ this.buffer.push({t:Date.now(),level,data}); if(this.buffer.length>this.limit) this.buffer.shift(); }
  latest(n=50){ return this.buffer.slice(-n); }
}
export const monitor = new Monitor();

# client/chango/audio/contextPool.js
import { device } from "../core/device.js";
export class AudioContextPool {
  constructor({ sampleRate = device.sampleRateHint } = {}){ this.sampleRate=sampleRate; this.ctx=null; this.master=null; this.unlocked=false; this._suspendTimer=null; }
  async ensure(){ if(!this.ctx){ const Ctx=window.AudioContext||window.webkitAudioContext; this.ctx=new Ctx({sampleRate:this.sampleRate}); this.master=this.ctx.createGain(); this.master.gain.value=1; this.master.connect(this.ctx.destination);} return this.ctx; }
  async unlock(){ await this.ensure(); if(this.ctx.state==="suspended"){ await this.ctx.resume(); } this.unlocked=true; this._autoSuspend(); }
  node(){ return this.master; }
  _autoSuspend(){ clearTimeout(this._suspendTimer); this._suspendTimer=setTimeout(async()=>{ try{ if(this.ctx && this.unlocked && this.ctx.state==="running"){ await this.ctx.suspend(); } }catch{} }, 30000); }
  async stop(){ clearTimeout(this._suspendTimer); if(this.ctx){ try{ await this.ctx.close(); }catch{} } this.ctx=null; this.master=null; this.unlocked=false; }
}
export const ctxPool = new AudioContextPool();

# client/chango/audio/vad.js
// VAD + permission validator + auto-recovery.
import { bus } from "../core/eventBus.js";
import { ctxPool } from "./contextPool.js";
import { device } from "../core/device.js";

export class VAD {
  constructor({ startThresh=0.015, stopThresh=0.008, minHoldMs=150 }={}) {
    this.startT=startThresh; this.stopT=stopThresh; this.minHold=minHoldMs/1000;
    this.media=null; this.node=null; this.state="idle"; this.lastStart=0; this.stream=null; this._recoveryTimer=null;
  }
  async _getStream(){ 
    try { 
      return await navigator.mediaDevices.getUserMedia({ audio: device.micConstraints, video:false }); 
    } catch (e) {
      bus.emit("diag:error",{where:"getUserMedia",e: e?.name||e?.message||e});
      throw e;
    }
  }
  async start(){
    await ctxPool.ensure(); const ctx=ctxPool.ctx;
    try { this.stream = await this._getStream(); } catch { return; }
    this.media = ctx.createMediaStreamSource(this.stream);
    const proc = ctx.createScriptProcessor(1024,1,1);
    const prev = new Float32Array(512); let prevMag=0;
    proc.onaudioprocess = (e)=>{
      const x = e.inputBuffer.getChannelData(0);
      let energy=0; for(let i=0;i<x.length;i++) energy += x[i]*x[i]; energy/=x.length;
      let mag=0; for(let i=0;i<prev.length;i++) mag += Math.abs(x[i]-prev[i]); prev.set(x.subarray(0,prev.length));
      const flux = Math.abs(mag - prevMag); prevMag=mag;
      const score = 0.85*energy + 0.15*(flux/prev.length);
      const t = ctx.currentTime;
      if(this.state==="idle" && score>this.startT){ this.state="speech"; this.lastStart=t; bus.emit("vad:start",{t,energy:score}); }
      else if(this.state==="speech" && score<this.stopT && (t-this.lastStart)>this.minHold){ this.state="idle"; bus.emit("vad:stop",{t,energy:score}); }
    };
    this.media.connect(proc); proc.connect(ctx.createGain()); this.node=proc;
    this._watchPermission();
  }
  async _watchPermission(){
    try {
      const perms = await navigator.permissions.query({ name:"microphone" });
      const onChange = ()=>{
        if(perms.state==="denied"){ bus.emit("diag:warn",{where:"mic",msg:"permission denied"}); this._attemptRecover(); }
      };
      perms.onchange = onChange;
    } catch {}
  }
  _attemptRecover(){
    clearTimeout(this._recoveryTimer);
    this._recoveryTimer = setTimeout(async ()=>{
      try { this.stop(); await this.start(); bus.emit("diag:info",{where:"mic",msg:"auto-recovered"}); }
      catch(e){ bus.emit("diag:error",{where:"mic",msg:"recovery failed",e:e?.message}); }
    }, 2000);
  }
  stop(){
    try{ this.node && this.node.disconnect(); }catch{}
    try{ this.media && this.media.disconnect(); }catch{}
    try{ this.stream && this.stream.getTracks().forEach(t=>t.stop()); }catch{}
    this.node=null; this.media=null; this.stream=null; this.state="idle";
  }
}

# client/chango/audio/mfcc.js
export class MFCC {
  constructor({ fftSize=1024, sampleRate=48000, melBands=24, coeffs=13 }={}) {
    this.fftSize=fftSize; this.sampleRate=sampleRate; this.melBands=melBands; this.coeffs=coeffs;
    this._hann=new Float32Array(fftSize); for(let i=0;i<fftSize;i++) this._hann[i]=0.5*(1-Math.cos(2*Math.PI*i/(fftSize-1)));
    this._fb=null;
  }
  _fftReIm(x){ const N=x.length; const re=x.slice(); const im=new Float32Array(N);
    for(let i=0,j=0;i<N;i++){ if(i<j){ [re[i],re[j]]=[re[j],re[i]]; [im[i],im[j]]=[im[j],im[i]]; } let m=N>>1; while(j>=m && m>=2){ j-=m; m>>=1; } j+=m; }
    for(let s=2;s<=N;s<<=1){ const h=s>>1, step=(2*Math.PI)/s; for(let i=0;i<N;i+=s){ for(let k=0;k<h;k++){ const ang=step*k, wr=Math.cos(ang), wi=-Math.sin(ang);
      const tr=wr*re[i+k+h]-wi*im[i+k+h], ti=wr*im[i+k+h]+wi*re[i+k+h]; re[i+k+h]=re[i+k]-tr; im[i+k+h]=im[i+k]-ti; re[i+k]+=tr; im[i+k]+=ti; } } }
    return {re,im}; }
  _hz2mel(hz){ return 2595*Math.log10(1+hz/700); } _mel2hz(m){ return 700*(Math.pow(10,m/2595)-1); }
  _melFilterbank(){ if(this._fb) return this._fb; const sr=this.sampleRate, nfft=this.fftSize, nb=this.melBands;
    const mMin=this._hz2mel(20), mMax=this._hz2mel(sr/2);
    const mpts=Array.from({length:nb+2},(_,i)=>mMin+i*(mMax-mMin)/(nb+1)).map(m=>this._mel2hz(m));
    const bins=mpts.map(f=>Math.floor((nfft+1)*f/sr));
    const fb=Array.from({length:nb},()=>new Float32Array(nfft/2+1));
    for(let i=0;i<nb;i++){ for(let k=bins[i];k<bins[i+1];k++) fb[i][k]=(k-bins[i])/Math.max(1,(bins[i+1]-bins[i]));
      for(let k=bins[i+1];k<bins[i+2];k++) fb[i][k]=(bins[i+2]-k)/Math.max(1,(bins[i+2]-bins[i+1])); }
    this._fb=fb; return fb; }
  _dct(mE){ const K=this.coeffs,N=mE.length,out=new Float32Array(K); for(let k=0;k<K;k++){ let s=0; for(let n=0;n<N;n++) s+=mE[n]*Math.cos(Math.PI*k*(2*n+1)/(2*N)); out[k]=s*Math.sqrt(2/N); } return out; }
  extract(frame){ const x=frame.slice(0,this.fftSize); for(let i=0;i<x.length;i++) x[i]*=this._hann[i]; const {re,im}=this._fftReIm(x);
    const mag=new Float32Array(re.length/2); for(let i=0;i<mag.length;i++) mag[i]=Math.hypot(re[i],im[i]);
    const fb=this._melFilterbank(), mel=new Float32Array(fb.length); for(let i=0;i<fb.length;i++){ let s=0; for(let k=0;k<fb[i].length;k++) s+=fb[i][k]*mag[k]; mel[i]=Math.log(1e-8+s); }
    return this._dct(mel); }
  voiceprint(frames){ const mf=frames.map(f=>this.extract(f)); const mean=new Float32Array(this.coeffs); for(const v of mf) for(let i=0;i<mean.length;i++) mean[i]+=v[i]; for(let i=0;i<mean.length;i++) mean[i]/=Math.max(1,mf.length); return mean; }
  cosine(a,b){ let s=0,na=0,nb=0; for(let i=0;i<a.length;i++){ s+=a[i]*b[i]; na+=a[i]*a[i]; nb+=b[i]*b[i]; } return s/(Math.sqrt(na)*Math.sqrt(nb)+1e-9); }
}

# client/chango/tts/prosody.js
export function prosodyPlan(text){
  const raw=(text||"").trim();
  const phrases=splitPhrases(raw).map(seg=>toUnits(seg));
  return phrases.flat();
}
function splitPhrases(t){
  return t.split(/([.?!,;:])/).reduce((acc,cur,idx)=>{
    if(!cur) return acc; if(" .?!,;:".includes(cur)&&idx>0){ acc[acc.length-1]+=cur; } else acc.push(cur); return acc;
  },[]).map(s=>s.trim()).filter(Boolean);
}
function toUnits(phrase){
  const isQ=/\?$/.test(phrase); const words=phrase.replace(/[.?!,;:]/g,"").split(/\s+/).filter(Boolean);
  return words.map((w,i)=>({ word:w, emphasis:/\*\*[^*]+\*\*/.test(w), boundary:(i===words.length-1)?(isQ?"H%":"L%"):(i%3===2?"ip":"none") }));
}

# client/chango/accent/engine.js
export function accentize(phonemes, profile="neutral"){
  const rules=profiles[profile]||profiles.neutral; const out=[];
  for(const ph of phonemes){ let sym=ph.ph; if(rules.vowel[sym]) sym=rules.vowel[sym]; if(rules.cons[sym]) sym=rules.cons[sym];
    out.push({ ...ph, ph:sym, dur:(ph.dur||1)*rules.tscale, gain:(ph.gain||1)*rules.gscale });
  } return out;
}
const profiles={ neutral:{vowel:{},cons:{},tscale:1,gscale:1}, uk_rp:{vowel:{ae:"aa",ah:"ax",er:"əː"},cons:{r:"ɹ"},tscale:1.05,gscale:0.95}, us_south:{vowel:{ih:"iy",ey:"eə",ay:"aə"},cons:{r:"ɻ"},tscale:0.95,gscale:1.02} };

# client/chango/tts/g2p.js
export function wordsToPhones(plan){
  const dict={ hello:["h","eh","l","ow"], world:["w","er","l","d"], chango:["ch","aa","ng","ow"], jarvis:["jh","aa","r","v","ih","s"] };
  const out=[]; for(const unit of plan){ const w=unit.word.toLowerCase().replace(/\*|_/g,""); const phs=dict[w]||fallbackGrapheme(w); for(const ph of phs) out.push({ph,dur:1,gain:1});
    out.push({ph:"pau", dur: unit.boundary==="H%"?1.4:unit.boundary==="ip"?0.7:0.5}); } return out;
}
export function fallbackGrapheme(w){ const seq=[]; for(let i=0;i<w.length;i++){ const c=w[i]; if("aeiou".includes(c)) seq.push(vowel(c,w[i+1]||"")); else seq.push(cons(c)); } return seq; }
export function vowel(v,n){ return v==="a"?(["e","y"].includes(n)?"ey":"ae"):v==="e"?"eh":v==="i"?"ih":v==="o"?(n==="w"?"ow":"ao"):v==="u"?"uw":"ah"; }
export function cons(c){ const map={b:"b",c:"k",d:"d",f:"f",g:"g",h:"h",j:"jh",k:"k",l:"l",m:"m",n:"n",p:"p",q:"k",r:"r",s:"s",t:"t",v:"v",w:"w",x:"k",y:"y",z:"z"}; return map[c]||"pau"; }
export function toTimeline(phs){ return phs.map(p=>({ ph:p.ph, dur:(p.dur||1)*0.08, gain:p.gain||1 })); }

# client/chango/tts/formantSynth.js
import { ctxPool } from "../audio/contextPool.js";
const VOWELS={ iy:[270,2290,3010], ih:[390,1990,2550], eh:[530,1840,2480], ae:[660,1720,2410], aa:[730,1090,2440], ah:[570,1580,2410], ao:[570,840,2410], uh:[440,1020,2240], uw:[300,870,2240], ow:[360,940,2280], ey:[530,1830,2480], ay:[660,1720,2410], oy:[500,1400,2400], er:[490,1350,1690] };
const CONS={ f:8000, s:6000, sh:3500, th:4000, v:7000, z:5000, zh:3000, ch:3000, jh:2300, h:2000, k:1800, g:1500, t:2500, d:2000, p:2800, b:2400, m:700, n:700, l:1000, r:500, w:600, y:1000, ng:500 };
export class FormantSynth{
  constructor(){ this.ctx=null; this.master=null; this.voices={ baseHz:120 }; }
  async ensure(){ await ctxPool.ensure(); this.ctx=ctxPool.ctx; this.master=ctxPool.node(); }
  async speak(timeline,{rate=1,pitch=1,volume=1}={}){ await this.ensure(); if(this.master) this.master.gain.value=volume; const start=this.ctx.currentTime+0.02; let t=start;
    for(const it of timeline){ const d=(it.dur||0.08)/rate; if(it.ph==="pau"){ t+=d; continue; } await this._render(it,t,d,pitch); t+=d*0.92; }
    return new Promise(r=>setTimeout(r,(t-this.ctx.currentTime)*1000));
  }
  async _render(it,t,d,pitch){ if(isVowel(it.ph)) this._vowel(it.ph,t,d,pitch,it.gain||0.22); else this._cons(it.ph,t,d,pitch,it.gain||0.12); }
  _vowel(v,t,d,pitch,gain){ const ctx=this.ctx; const src=ctx.createOscillator(); src.type="sawtooth"; src.frequency.setValueAtTime((this.voices.baseHz||120)*pitch,t);
    const lfo=ctx.createOscillator(); lfo.type="triangle"; lfo.frequency.value=5+Math.random()*2; const lfoG=ctx.createGain(); lfoG.gain.value=0.006; lfo.connect(lfoG); lfoG.connect(src.frequency);
    const pre=ctx.createGain(); pre.gain.value=gain; const [f1,f2,f3]=VOWELS[v]||VOWELS.ah; const b1=bp(ctx,f1*pitch,20), b2=bp(ctx,f2*pitch,40), b3=bp(ctx,f3*pitch,60); const nasal=bp(ctx,250,8);
    src.connect(pre); pre.connect(b1); pre.connect(b2); pre.connect(b3); pre.connect(nasal); const sum=ctx.createGain(); b1.connect(sum); b2.connect(sum); b3.connect(sum); nasal.connect(sum);
    const asp=noise(ctx); const hp=ctx.createBiquadFilter(); hp.type="highpass"; hp.frequency.value=6000; asp.connect(hp); hp.connect(sum);
    const env=ctx.createGain(); env.gain.value=0.0001; sum.connect(env); env.connect(this.master);
    env.gain.setValueAtTime(0.0001,t); env.gain.exponentialRampToValueAtTime(1.0,t+Math.min(0.015,d*0.2)); env.gain.setValueAtTime(1.0,t+Math.max(0.01,d*0.7)); env.gain.exponentialRampToValueAtTime(0.0001,t+d);
    src.start(t); lfo.start(t); src.stop(t+d); lfo.stop(t+d);
  }
  _cons(ph,t,d,pitch,gain){ const ctx=this.ctx; const n=noise(ctx); const b=bp(ctx,CONS[ph]||2000,100); const g=ctx.createGain(); g.gain.value=gain; n.connect(b); b.connect(g); g.connect(this.master);
    const atk=Math.min(0.006,d*0.3), rel=Math.min(0.03,d*0.5); g.gain.setValueAtTime(0.0001,t); g.gain.exponentialRampToValueAtTime(gain,t+atk); g.gain.exponentialRampToValueAtTime(0.0001,t+d-rel);
    if(["m","n","l","r","v","z","w","y","jh","zh","ng"].includes(ph)){ const o=ctx.createOscillator(); o.type="triangle"; o.frequency.value=100*pitch; const vg=ctx.createGain(); vg.gain.value=0.06; o.connect(vg); vg.connect(this.master); o.start(t); o.stop(t+d); }
    n.start(t); n.stop(t+d);
  }
}
function bp(ctx,f,Q){ const bi=ctx.createBiquadFilter(); bi.type="bandpass"; bi.frequency.value=f; bi.Q.value=Q; return bi; }
function noise(ctx){ const b=ctx.createBuffer(1,ctx.sampleRate*2,ctx.sampleRate); const d=b.getChannelData(0); for(let i=0;i<d.length;i++) d[i]=(Math.random()*2-1)*0.6; const s=ctx.createBufferSource(); s.buffer=b; s.loop=true; return s; }
function isVowel(p){ return Object.prototype.hasOwnProperty.call(VOWELS,p); }

# client/chango/wakeword/detector.js
import { bus } from "../core/eventBus.js"; import { MFCC } from "../audio/mfcc.js";
export class WakeWordDetector{
  constructor({name="lolo",thresh=0.72}={}){ this.name=name; this.thresh=thresh; this.mfcc=new MFCC(); this.templates=[]; }
  enroll(frames){ this.templates.push(frames); }
  score(seq,tmpl){ const L=Math.min(seq.length,tmpl.length); let s=0; for(let i=0;i<L;i++) s+=this.mfcc.cosine(seq[i],tmpl[i]); return s/L; }
  detect(seq){ let best=-1; for(const t of this.templates) best=Math.max(best,this.score(seq,t)); if(best>=this.thresh) bus.emit("wake:hit",{phrase:this.name,score:best}); }
}

# client/chango/stt/webspeech.js
// STT with handover rules using SpeechState.
import { bus } from "../core/eventBus.js"; import { speechState } from "../core/state.js";
export class WebSpeechSTT {
  constructor(){ this.rec=null; this.active=false; this._debounceTimer=null; }
  start(){ const SR=window.SpeechRecognition||window.webkitSpeechRecognition; if(!SR){ bus.emit("stt:unavailable"); return; }
    this.rec=new SR(); this.rec.continuous=true; this.rec.interimResults=true;
    this.rec.onresult=(e)=>{ const i=e.resultIndex, r=e.results[i]; const txt=r[0].transcript; if(!speechState.guardIncoming(txt)) return;
      clearTimeout(this._debounceTimer); this._debounceTimer=setTimeout(()=>{ bus.emit("stt:result",{ text:txt.trim(), final:r.isFinal }); }, r.isFinal?0:120);
    };
    this.rec.onend=()=>{ if(this.active) this.rec.start(); };
    try{ this.rec.start(); this.active=true; }catch{}
  }
  stop(){ try{ this.rec&&this.rec.stop(); }catch{} this.active=false; }
}

# client/chango/ui/adapter.js
import { bus } from "../core/eventBus.js";
export class UIAdapter{
  constructor(){ this.el={ enable:q('[data-chango-enable]'), speak:q('[data-chango-speak]'), stop:q('[data-chango-stop]'), text:q('[data-chango-text]'), status:q('[data-chango-status]') }; }
  mount({speakFn,stopFn,unlockFn}){ this.el.enable&&this.el.enable.addEventListener("click",unlockFn); this.el.speak&&this.el.speak.addEventListener("click",()=>speakFn(this.text())); this.el.stop&&this.el.stop.addEventListener("click",stopFn);
    bus.on("status", s=>this.status(s)); bus.on("vad:start",()=>this.status("listening…")); bus.on("vad:stop",()=>this.status("idle")); bus.emit("status","idle"); }
  text(){ return this.el.text?(this.el.text.value||this.el.text.textContent||""):""; }
  status(s){ if(!this.el.status) return; this.el.status.textContent=s; }
}
function q(sel){ return document.querySelector(sel); }

# client/chango/dev/overlay.js
// Dev overlay (default OFF), toggle via Alt+Shift+D OR ?changoDev=1 / localStorage.
import { bus } from "../core/eventBus.js";
export class PhonemeOverlay{
  constructor(){ this.enabled=this._shouldEnable(); this.root=null; this.canvas=null; this.ctx=null;
    if(this.enabled) this._mount(); bus.on("tts:timeline",p=>{ if(this.enabled) this._draw(p); });
    window.addEventListener("keydown",(e)=>{ if(e.altKey&&e.shiftKey&&e.code==="KeyD"){ this.enabled=!this.enabled; try{ localStorage.setItem("changoDev", this.enabled?"1":"0"); }catch{} if(this.enabled && !this.root) this._mount(); if(this.root) this.root.style.display=this.enabled?"block":"none"; }});
  }
  _shouldEnable(){ const qs=new URLSearchParams(location.search); if(qs.get("changoDev")==="1") return true; try{ return localStorage.getItem("changoDev")==="1"; }catch{ return false; } }
  _mount(){ this.root=document.createElement("div"); Object.assign(this.root.style,{position:"fixed",left:"0",right:"0",bottom:"0",height:"120px",pointerEvents:"none",zIndex:"2147483647",background:"linear-gradient(180deg,transparent,rgba(0,0,0,0.35))",display:"none"});
    this.canvas=document.createElement("canvas"); this.canvas.width=window.innerWidth; this.canvas.height=120; this.root.appendChild(this.canvas); document.body.appendChild(this.root); this.ctx=this.canvas.getContext("2d");
    window.addEventListener("resize",()=>{ this.canvas.width=window.innerWidth; }); }
  _draw({items}){ if(!this.ctx) return; this.root.style.display="block"; const ctx=this.ctx; ctx.clearRect(0,0,this.canvas.width,this.canvas.height);
    const total=items.reduce((s,i)=>s+i.dur,0); let x=10; const h=60; const y=40; const scale=Math.max(1,(this.canvas.width-20)/(total*1000));
    for(const it of items){ const w=Math.max(2,it.dur*1000*scale); ctx.fillStyle=it.ph==="pau"?"rgba(200,200,200,0.35)":"rgba(140,200,255,0.7)"; ctx.fillRect(x,y,w,h); ctx.fillStyle="#fff"; ctx.font="12px ui-monospace"; ctx.fillText(it.ph,x+2,y+14); x+=w+4; } }
}

# client/chango/bootstrap.js
// Headless bootstrap: preserves your UI; only binds behaviors.
import { bus } from "./core/eventBus.js";
import { ctxPool } from "./audio/contextPool.js";
import { VAD } from "./audio/vad.js";
import { MFCC } from "./audio/mfcc.js";
import { prosodyPlan } from "./tts/prosody.js";
import { accentize } from "./accent/engine.js";
import { FormantSynth } from "./tts/formantSynth.js";
import { WakeWordDetector } from "./wakeword/detector.js";
import { WebSpeechSTT } from "./stt/webspeech.js";
import { UIAdapter } from "./ui/adapter.js";
import { wordsToPhones, toTimeline } from "./tts/g2p.js";
import { PhonemeOverlay } from "./dev/overlay.js";
import { speechState } from "./core/state.js";
import { monitor } from "./../diag/monitor.js";

const ui=new UIAdapter(); const vad=new VAD(); const mfcc=new MFCC(); const tts=new FormantSynth(); const stt=new WebSpeechSTT(); const wake=new WakeWordDetector({name:"lolo"}); new PhonemeOverlay();
// placeholder wake template (user must enroll real one later)
wake.enroll(Array.from({length:12},()=>new Float32Array(13)));

function unlock(){ ctxPool.unlock().then(()=>bus.emit("status","ready")).catch(()=>bus.emit("status","error: audio")); }

async function speak(text){
  if(!text||!text.trim()){ bus.emit("status","nothing to say"); return; }
  speechState.set("speaking","user");
  const plan=prosodyPlan(text); const ph=wordsToPhones(plan); const acc=accentize(ph,"neutral"); const tl=toTimeline(acc);
  bus.emit("tts:timeline",{items:tl});
  try{ await tts.speak(tl,{rate:1,pitch:1,volume:1}); } catch(e){ bus.emit("diag:error",{where:"tts",e:e?.message}); }
  speechState.set("idle","done");
  bus.emit("status","idle");
}
function stop(){ ctxPool.stop(); speechState.set("idle","stop"); bus.emit("status","stopped"); }

// Mount without changing your HTML/CSS
ui.mount({speakFn:speak, stopFn:stop, unlockFn:unlock});

// Optional continuous loop; safe due to state machine & VAD
(async()=>{ try{ await vad.start(); }catch{} stt.start(); })();

# tests/eventBus.test.js
import { EventBus } from "../client/chango/core/eventBus.js";
test("event bus on/emit/off",()=>{ const b=new EventBus(); let c=0; const off=b.on("x",(p)=>{c+=p;}); b.emit("x",2); expect(c).toBe(2); off(); b.emit("x",3); expect(c).toBe(2); });

# tests/prosody.test.js
import { prosodyPlan } from "../client/chango/tts/prosody.js";
test("prosody end boundary",()=>{ const out=prosodyPlan("Hello world?"); expect(out.at(-1).boundary).toBe("H%"); });

# tests/accent.test.js
import { accentize } from "../client/chango/accent/engine.js";
test("accent mapping + scaling",()=>{ const out=accentize([{ph:"ae",dur:1,gain:1}],"uk_rp"); expect(out[0].ph).not.toBe("ae"); });

# tests/mfcc.test.js
import { MFCC } from "../client/chango/audio/mfcc.js";
test("MFCC stable tone",()=>{ const sr=48000,N=1024,f=440; const frame=new Float32Array(N); for(let i=0;i<N;i++) frame[i]=Math.sin(2*Math.PI*f*i/sr);
  const mf=new MFCC({fftSize:N,sampleRate:sr}); const a=mf.extract(frame), b=mf.extract(frame); let diff=0; for(let i=0;i<a.length;i++) diff+=Math.abs(a[i]-b[i]); expect(diff).toBeLessThan(1e-6); });

# tests/g2p_timeline.test.js
import { wordsToPhones, toTimeline } from "../client/chango/tts/g2p.js";
test("wordsToPhones + pause",()=>{ const seq=wordsToPhones([{word:"hello",boundary:"none"},{word:"world",boundary:"L%"}]); expect(seq.at(-1).ph).toBe("pau"); });
test("toTimeline scaling",()=>{ const tl=toTimeline([{ph:"eh",dur:2},{ph:"pau",dur:0.5}]); expect(tl[0].dur).toBeCloseTo(0.16,3); });

# server/cli/tts_render.mjs
#!/usr/bin/env node
/**
 * CLI: render text to WAV using Chango's formant TTS (Node, no deps).
 * Usage: node server/cli/tts_render.mjs --text "hello" --out out.wav --rate 1 --pitch 1 --sr 48000
 */
import fs from "node:fs";
import path from "node:path";

// --- Args
const args = Object.fromEntries(process.argv.slice(2).map((a,i,arr)=> a.startsWith("--") ? [a.slice(2), arr[i+1] && !arr[i+1].startsWith("--") ? arr[i+1] : true] : [] ).filter(Boolean));
const TEXT = (args.text||"Hello from Chango.").toString();
const OUT  = path.resolve(args.out||"./out.wav");
const SR   = Number(args.sr||48000);
const RATE = Number(args.rate||1);
const PITCH= Number(args.pitch||1);

// --- Prosody & G2P (mirror client)
function prosodyPlan(text){ const raw=(text||"").trim(); return splitPhrases(raw).map(seg=>toUnits(seg)).flat(); }
function splitPhrases(t){ return t.split(/([.?!,;:])/).reduce((a,c,i)=>{ if(!c) return a; if(" .?!,;:".includes(c)&&i>0){ a[a.length-1]+=c; } else a.push(c); return a;},[]).map(s=>s.trim()).filter(Boolean);}
function toUnits(phrase){ const isQ=/\?$/.test(phrase); const words=phrase.replace(/[.?!,;:]/g,"").split(/\s+/).filter(Boolean);
  return words.map((w,i)=>({word:w, boundary:(i===words.length-1)?(isQ?"H%":"L%"):(i%3===2?"ip":"none") }));}
function vowel(v,n){ return v==="a"?(["e","y"].includes(n)?"ey":"ae"):v==="e"?"eh":v==="i"?"ih":v==="o"?(n==="w"?"ow":"ao"):v==="u"?"uw":"ah"; }
function cons(c){ const map={b:"b",c:"k",d:"d",f:"f",g:"g",h:"h",j:"jh",k:"k",l:"l",m:"m",n:"n",p:"p",q:"k",r:"r",s:"s",t:"t",v:"v",w:"w",x:"k",y:"y",z:"z"}; return map[c]||"pau"; }
function fallbackGrapheme(w){ const seq=[]; for(let i=0;i<w.length;i++){ const c=w[i]; if("aeiou".includes(c)) seq.push(vowel(c,w[i+1]||"")); else seq.push(cons(c)); } return seq; }
function wordsToPhones(plan){ const dict={ hello:["h","eh","l","ow"], world:["w","er","l","d"], chango:["ch","aa","ng","ow"], jarvis:["jh","aa","r","v","ih","s"] };
  const out=[]; for(const u of plan){ const w=u.word.toLowerCase(); const phs=dict[w]||fallbackGrapheme(w); for(const ph of phs) out.push({ph,dur:1,gain:1}); out.push({ph:"pau", dur:u.boundary==="H%"?1.4:u.boundary==="ip"?0.7:0.5}); } return out; }
function toTimeline(phs){ return phs.map(p=>({ ph:p.ph, dur:(p.dur||1)*0.08, gain:p.gain||1 })); }

// --- Synth (Node DSP)
const VOWELS={ iy:[270,2290,3010], ih:[390,1990,2550], eh:[530,1840,2480], ae:[660,1720,2410], aa:[730,1090,2440], ah:[570,1580,2410], ao:[570,840,2410], uh:[440,1020,2240], uw:[300,870,2240], ow:[360,940,2280], ey:[530,1830,2480], ay:[660,1720,2410], oy:[500,1400,2400], er:[490,1350,1690] };
const CONS={ f:8000, s:6000, sh:3500, th:4000, v:7000, z:5000, zh:3000, ch:3000, jh:2300, h:2000, k:1800, g:1500, t:2500, d:2000, p:2800, b:2400, m:700, n:700, l:1000, r:500, w:600, y:1000, ng:500 };
function isVowel(p){ return Object.prototype.hasOwnProperty.call(VOWELS,p); }

// Simple biquad bandpass (Direct Form I)
function biquadBandpass(fc,Q,sr){ const w0=2*Math.PI*fc/sr; const alpha=Math.sin(w0)/(2*Q); const cos=Math.cos(w0);
  const b0= Q*alpha, b1=0, b2=-Q*alpha, a0=1+alpha, a1=-2*cos, a2=1-alpha;
  const bz=[b0/a0,b1/a0,b2/a0], az=[1,a1/a0,a2/a0]; const x=[0,0,0], y=[0,0,0];
  return (v)=>{ x[0]=v; const out=bz[0]*x[0]+bz[1]*x[1]+bz[2]*x[2]-az[1]*y[1]-az[2]*y[2]; x[2]=x[1]; x[1]=x[0]; y[2]=y[1]; y[1]=out; return out; };
}
function noise(){ let z=1234567; return ()=>{ z=(1103515245*z+12345)|0; return ((z>>>16)&0x7fff)/0x7fff*2-1; }; }

function synthTimeline(tl,{rate=RATE,pitch=PITCH,sr=SR,baseHz=120}={}){
  const totalDur = tl.reduce((s,i)=>s+i.dur,0)/rate;
  const totalN = Math.ceil(totalDur*sr)+1;
  const out = new Float32Array(totalN);
  let tSec=0, idx=0;
  for(const it of tl){
    const d = it.dur/rate; const n = Math.max(1, Math.floor(d*sr));
    if(it.ph==="pau"){ tSec+=d; idx+=n; continue; }
    if(isVowel(it.ph)){
      const [f1,f2,f3] = VOWELS[it.ph]||VOWELS.ah;
      const bp1=biquadBandpass(f1*pitch,20,sr), bp2=biquadBandpass(f2*pitch,40,sr), bp3=biquadBandpass(f3*pitch,60,sr);
      const asp=noise(); const jitter=noise(); let phase=0;
      for(let i=0;i<n;i++){
        const f0=(baseHz*pitch) * (1 + 0.004*jitter()); 
        phase += (2*Math.PI*f0)/sr; if(phase>Math.PI*2) phase-=Math.PI*2;
        const saw= (2*(phase/(2*Math.PI)) -1); // cheap saw
        const v = bp1(saw*0.12) + bp2(saw*0.08) + bp3(saw*0.06) + (asp()*0.01);
        const env = envelope(i,n);
        out[idx+i] += v*env;
      }
    } else {
      const center = CONS[it.ph]||2000; const bp=biquadBandpass(center,100,sr); const nsrc=noise();
      for(let i=0;i<n;i++){ const env=envelope(i,n); out[idx+i]+= bp(nsrc()*0.15)*env; }
      if(["m","n","l","r","v","z","w","y","jh","zh","ng"].includes(it.ph)){
        let phase=0; for(let i=0;i<n;i++){ phase+=(2*Math.PI*(100*pitch))/sr; if(phase>Math.PI*2) phase-=Math.PI*2; out[idx+i]+= Math.sin(phase)*0.03*envelope(i,n); }
      }
    }
    tSec+=d; idx+=n;
  }
  // normalize
  let peak=1e-6; for(const v of out) peak=Math.max(peak,Math.abs(v)); const g=0.95/peak; for(let i=0;i<out.length;i++) out[i]*=g;
  return out;
}
function envelope(i,n){ const a=Math.min(0.02, n*0.2/sr), r=Math.min(0.04, n*0.2/sr); const ii=i/sr; const dd=n/sr;
  if(ii<a) return ii/a; if(ii>dd-r) return (dd-ii)/r; return 1; }

// Write WAV 16-bit PCM
function writeWav(samples,sr,outPath){
  const numChannels=1, bits=16, byteRate=sr*numChannels*bits/8, blockAlign=numChannels*bits/8;
  const dataLen=samples.length*2, fileLen=44+dataLen-8;
  const buf = Buffer.alloc(44+dataLen);
  let p=0; const W=(s)=>{ buf.writeUInt32LE(s,p); p+=4; }, w=(s)=>{ buf.writeUInt16LE(s,p); p+=2; }, b=(s)=>{ buf.writeInt16LE(s,p); p+=2; };
  buf.write("RIFF",0,4,"ascii"); W(fileLen); buf.write("WAVE",8,4,"ascii");
  buf.write("fmt ",12,4,"ascii"); W(16); w(1); w(numChannels); W(sr); W(byteRate); w(blockAlign); w(bits);
  buf.write("data",36,4,"ascii"); W(dataLen);
  p=44; for(const f of samples){ const s=Math.max(-1,Math.min(1,f)); b(s*32767); }
  fs.writeFileSync(outPath,buf);
}

// Run
const plan=prosodyPlan(TEXT); const seq=wordsToPhones(plan); const tl=toTimeline(seq);
const pcm=synthTimeline(tl,{rate:RATE,pitch:PITCH,sr:SR,baseHz:120});
writeWav(pcm,SR,OUT);
console.log(`Wrote: ${OUT} (${pcm.length} samples @ ${SR}Hz)`);


⸻

Notes (why it matters):
	•	CLI WAV export enables offline generation for cars/computers/devices that can’t host a browser; same voice, same pipeline.
	•	Alt+Shift+D toggles dev overlay; default remains OFF; no banner/UI changes.
	•	SpeechState stops repetition loops by locking out STT while TTS speaks and deduping transcripts.
	•	Mic validator auto-recovers if browser revokes mic permission.
	•	Device auto-adapt tunes sample rate & mic constraints for mobile/car/desktop.

a. Want me to add a small owner voiceprint enroll/match API (store MFCC mean + threshold) and wire it to “respond only to owner”?
b. Should I add a wake-word template recorder (10s capture → template store) to improve “Lolo” accuracy?