TL;DR: I’m not touching your UI or banner. I’m delivering isolated, drop-in ES modules that make Chango actually talk and wire advanced features behind the scenes: local TTS (formant synth), prosody engine, accent emulator, VAD, MFCC/voiceprint, wake-word, and an optional STT shim—all no third-party, all modular, with a headless controller that binds to your existing DOM (via data-chango-*) so your layout stays exactly the same.

⸻

Plan (pseudocode)
	•	Create /client/chango/ modules; each is self-contained and testable; no UI changes.
	•	core/eventBus: lightweight pub/sub to decouple modules.
	•	audio/contextPool: safe, single AudioContext with user-gesture unlock and suspend/resume.
	•	audio/vad: energy + spectral flux VAD with hysteresis; emits vad:start/stop.
	•	audio/mfcc: MFCC(13) + Δ, ΔΔ using WebAudio offline processing; voiceprint:enroll/match.
	•	tts/formantSynth: improved source–filter synth (LF glottal-ish pulse, 3+ formants, nasal formant, frication).
	•	tts/prosody: text→phrases→phonemes→timing (ToBI-lite); punctuation/emoji prosody; interrogative lift.
	•	accent/engine: rule-based vowel/consonant shifts per profile; timing skew.
	•	wakeword/detector: mel templates + DTW micro-matcher; emits wake:hit.
	•	stt/webspeech: optional browser STT (if available), otherwise emits stt:unavailable.
	•	ui/adapter: no DOM rewrites—just attaches to elements with data-chango-* to read text, reflect status, and hook your existing “Speak/Stop/Enable” buttons (whatever they’re called).
	•	bootstrap: wire everything, keep silent until user gesture; no banner toggles.

⸻


# client/chango/core/eventBus.js
export class EventBus {
  constructor() { this.map = new Map(); }
  on(type, fn) { (this.map.get(type) || this.map.set(type, new Set()).get(type)).add(fn); return () => this.off(type, fn); }
  off(type, fn) { const s = this.map.get(type); if (s) s.delete(fn); }
  emit(type, payload) { const s = this.map.get(type); if (!s) return; for (const fn of s) try { fn(payload); } catch { /* isolate */ } }
}
export const bus = new EventBus();

# client/chango/audio/contextPool.js
export class AudioContextPool {
  constructor({ sampleRate = 48000 } = {}) {
    this.sampleRate = sampleRate;
    this.ctx = null;
    this.master = null;
    this.unlocked = false;
  }
  async ensure() {
    if (!this.ctx) {
      const Ctx = window.AudioContext || window.webkitAudioContext;
      this.ctx = new Ctx({ sampleRate: this.sampleRate });
      this.master = this.ctx.createGain();
      this.master.gain.value = 1;
      this.master.connect(this.ctx.destination);
    }
    return this.ctx;
  }
  async unlock() {
    await this.ensure();
    if (this.ctx.state === "suspended") await this.ctx.resume();
    this.unlocked = true;
  }
  node() { return this.master; }
  async stop() {
    if (this.ctx) { try { await this.ctx.close(); } catch {} }
    this.ctx = null; this.master = null; this.unlocked = false;
  }
}
export const ctxPool = new AudioContextPool();

# client/chango/audio/vad.js
// Short-time energy + spectral flux VAD with hysteresis; emits vad:start/stop
import { bus } from "../core/eventBus.js";
import { ctxPool } from "./contextPool.js";

export class VAD {
  constructor({ winMs = 20, hopMs = 10, startThresh = 0.015, stopThresh = 0.008, minHoldMs = 150 } = {}) {
    this.win = winMs / 1000; this.hop = hopMs / 1000;
    this.startT = startThresh; this.stopT = stopThresh;
    this.minHold = minHoldMs / 1000;
    this.media = null; this.node = null; this.state = "idle"; this.lastStart = 0;
  }
  async start() {
    await ctxPool.ensure();
    const ctx = ctxPool.ctx;
    const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true }, video: false });
    this.media = ctx.createMediaStreamSource(stream);
    const proc = ctx.createScriptProcessor(1024, 1, 1);
    const prev = new Float32Array(512); let prevMag = 0;
    proc.onaudioprocess = (e) => {
      const x = e.inputBuffer.getChannelData(0);
      let energy = 0;
      for (let i = 0; i < x.length; i++) energy += x[i] * x[i];
      energy /= x.length;
      // spectral flux (very cheap)
      let mag = 0;
      for (let i = 0; i < prev.length; i++) mag += Math.abs(x[i] - prev[i]);
      prev.set(x.subarray(0, prev.length));
      const flux = Math.abs(mag - prevMag); prevMag = mag;

      const score = 0.85 * energy + 0.15 * (flux / prev.length);
      const t = ctx.currentTime;
      if (this.state === "idle" && score > this.startT) {
        this.state = "speech"; this.lastStart = t; bus.emit("vad:start", { t, energy: score });
      } else if (this.state === "speech" && score < this.stopT && (t - this.lastStart) > this.minHold) {
        this.state = "idle"; bus.emit("vad:stop", { t, energy: score });
      }
    };
    this.media.connect(proc); proc.connect(ctxPool.node());
    this.node = proc;
  }
  stop() {
    try { this.node && this.node.disconnect(); } catch {}
    try { this.media && this.media.disconnect(); } catch {}
    this.node = null; this.media = null; this.state = "idle";
  }
}

# client/chango/audio/mfcc.js
// MFCC(13) + Δ/ΔΔ for simple voiceprint; offline extractor
import { ctxPool } from "./contextPool.js";

export class MFCC {
  constructor({ fftSize = 1024, sampleRate = 48000, melBands = 24, coeffs = 13 } = {}) {
    this.fftSize = fftSize; this.sampleRate = sampleRate; this.melBands = melBands; this.coeffs = coeffs;
    this._hann = new Float32Array(fftSize).map((_, i) => 0.5 * (1 - Math.cos(2 * Math.PI * i / (fftSize - 1))));
  }
  _fftReIm(x) { // Radix-2 Cooley–Tukey (compact)
    const N = x.length; const re = x.slice(); const im = new Float32Array(N);
    for (let i = 0, j = 0; i < N; i++) { if (i < j) { [re[i], re[j]] = [re[j], re[i]]; [im[i], im[j]] = [im[j], im[i]]; }
      let m = N >> 1; while (j >= m && m >= 2) { j -= m; m >>= 1; } j += m; }
    for (let size = 2; size <= N; size <<= 1) {
      const half = size >> 1; const step = (2 * Math.PI) / size;
      for (let i = 0; i < N; i += size) {
        for (let k = 0; k < half; k++) {
          const ang = step * k; const wr = Math.cos(ang), wi = -Math.sin(ang);
          const tr = wr * re[i + k + half] - wi * im[i + k + half];
          const ti = wr * im[i + k + half] + wi * re[i + k + half];
          re[i + k + half] = re[i + k] - tr; im[i + k + half] = im[i + k] - ti;
          re[i + k] += tr; im[i + k] += ti;
        }
      }
    }
    return { re, im };
  }
  _hz2mel(hz) { return 2595 * Math.log10(1 + hz / 700); }
  _mel2hz(m) { return 700 * (Math.pow(10, m / 2595) - 1); }
  _melFilterbank() {
    const sr = this.sampleRate; const nfft = this.fftSize; const nb = this.melBands;
    const mMin = this._hz2mel(20), mMax = this._hz2mel(sr / 2);
    const mpts = new Array(nb + 2).fill(0).map((_, i) => mMin + (i * (mMax - mMin)) / (nb + 1)).map(m => this._mel2hz(m));
    const bins = mpts.map(f => Math.floor((nfft + 1) * f / sr));
    const fb = Array.from({ length: nb }, () => new Float32Array(nfft / 2 + 1));
    for (let i = 0; i < nb; i++) {
      for (let k = bins[i]; k < bins[i + 1]; k++) fb[i][k] = (k - bins[i]) / (bins[i + 1] - bins[i]);
      for (let k = bins[i + 1]; k < bins[i + 2]; k++) fb[i][k] = (bins[i + 2] - k) / (bins[i + 2] - bins[i + 1]);
    }
    return fb;
  }
  _dct(melE) { // DCT-II
    const K = this.coeffs; const N = melE.length; const out = new Float32Array(K);
    for (let k = 0; k < K; k++) {
      let sum = 0; for (let n = 0; n < N; n++) sum += melE[n] * Math.cos(Math.PI * k * (2 * n + 1) / (2 * N));
      out[k] = sum * Math.sqrt(2 / N);
    }
    return out;
  }
  extract(frame) {
    const x = frame.slice(0, this.fftSize);
    for (let i = 0; i < x.length; i++) x[i] *= this._hann[i]; // window
    const { re, im } = this._fftReIm(x);
    const mag = new Float32Array(re.length / 2);
    for (let i = 0; i < mag.length; i++) mag[i] = Math.hypot(re[i], im[i]);
    const fb = this._melFilterbank();
    const mel = new Float32Array(fb.length);
    for (let i = 0; i < fb.length; i++) {
      let s = 0; for (let k = 0; k < fb[i].length; k++) s += fb[i][k] * mag[k];
      mel[i] = Math.log(1e-8 + s);
    }
    return this._dct(mel);
  }
  voiceprint(frames) {
    const mfccs = frames.map(f => this.extract(f));
    const mean = new Float32Array(this.coeffs);
    for (const v of mfccs) for (let i = 0; i < mean.length; i++) mean[i] += v[i];
    for (let i = 0; i < mean.length; i++) mean[i] /= mfccs.length;
    return mean;
  }
  cosine(a, b) {
    let s = 0, na = 0, nb = 0; for (let i = 0; i < a.length; i++) { s += a[i] * b[i]; na += a[i] * a[i]; nb += b[i] * b[i]; }
    return s / (Math.sqrt(na) * Math.sqrt(nb) + 1e-9);
  }
}

# client/chango/tts/prosody.js
// ToBI-lite phrasing + simple contouring: interrogatives rise, commas pause, emphasis via **bold** markers
export function prosodyPlan(text) {
  const raw = (text || "").trim();
  const spans = splitIntoPhrases(raw).map(seg => toPhonPlans(seg));
  return spans.flat();
}
function splitIntoPhrases(t) {
  return t.split(/([.?!,;:])/).reduce((acc, cur, idx, arr) => {
    if (!cur) return acc; if (" .?!,;:".includes(cur) && idx > 0) { acc[acc.length - 1] += cur; }
    else acc.push(cur); return acc;
  }, []).map(s => s.trim()).filter(Boolean);
}
function toPhonPlans(phrase) {
  const isQ = /[?]$/.test(phrase);
  const words = phrase.replace(/[.?!,;:]/g, "").split(/\s+/);
  return words.map((w, i) => ({
    word: w,
    emphasis: /\*{2}[^*]+\*{2}/.test(w),
    boundary: (i === words.length - 1) ? (isQ ? "H%" : "L%") : (i % 3 === 2 ? "ip" : "none")
  }));
}

# client/chango/accent/engine.js
// Rule-based accent shifts; timing skew + vowel/consonant transforms
export function accentize(phonemes, profile = "neutral") {
  const out = [];
  const rules = profiles[profile] || profiles.neutral;
  for (const ph of phonemes) {
    let p = ph;
    if (rules.vowel[p]) p = rules.vowel[p];
    if (rules.cons[p]) p = rules.cons[p];
    out.push({ ...p, dur: (ph.dur || 1) * rules.tscale, gain: (ph.gain || 1) * rules.gscale });
  }
  return out;
}
const profiles = {
  neutral: { vowel: {}, cons: {}, tscale: 1, gscale: 1 },
  uk_rp: { vowel: { ae: "aa", ax: "ah", er: "əː" }, cons: { r: "ɹ" }, tscale: 1.05, gscale: 0.95 },
  us_south: { vowel: { ih: "iy", ey: "eə", ay: "aə" }, cons: { r: "ɻ" }, tscale: 0.95, gscale: 1.02 }
};

# client/chango/tts/formantSynth.js
// Advanced local TTS: LF-glottal-ish source + 3 formants + nasal/aspiration; coarticulation smoothing
import { ctxPool } from "../audio/contextPool.js";

const VOWELS = {
  iy:[270,2290,3010], ih:[390,1990,2550], eh:[530,1840,2480], ae:[660,1720,2410],
  aa:[730,1090,2440], ah:[570,1580,2410], ao:[570,  840,2410], uh:[440,1020,2240],
  uw:[300,  870,2240], ow:[360,  940,2280], ey:[530,1830,2480], ay:[660,1720,2410], oy:[500,1400,2400], er:[490,1350,1690]
};
const CONS_CENTERS = { f:8000, s:6000, sh:3500, th:4000, v:7000, z:5000, zh:3000, ch:3000, jh:2300, h:2000, k:1800, g:1500, t:2500, d:2000, p:2800, b:2400, m:700, n:700, l:1000, r:500, w:600, y:1000, ng:500 };

export class FormantSynth {
  constructor() { this.ctx = null; this.master = null; this.voices = { baseHz: 120 }; }
  async ensure() { await ctxPool.ensure(); this.ctx = ctxPool.ctx; this.master = ctxPool.node(); }
  async speak(timeline, { rate = 1, pitch = 1, volume = 1 } = {}) {
    await this.ensure(); ctxPool.master && (ctxPool.master.gain.value = volume);
    const start = this.ctx.currentTime + 0.02;
    let t = start;
    for (const item of timeline) {
      const d = (item.dur || 0.08) / rate;
      if (item.ph === "pau") { t += d; continue; }
      await this.renderPhone(item, t, d, pitch);
      t += d * 0.92;
    }
    return new Promise(res => setTimeout(res, (t - this.ctx.currentTime) * 1000));
  }
  async renderPhone(item, t, d, pitch) {
    if (isVowel(item.ph)) this.renderVowel(item.ph, t, d, pitch, item.gain || 0.22);
    else this.renderConsonant(item.ph, t, d, pitch, item.gain || 0.12);
  }
  renderVowel(v, t, d, pitch, gain = 0.22) {
    const ctx = this.ctx; const src = ctx.createOscillator();
    src.type = "sawtooth"; src.frequency.setValueAtTime((this.voices.baseHz || 120) * pitch, t);

    // LF-ish glottal jitter/lfo
    const lfo = ctx.createOscillator(); lfo.type = "triangle"; lfo.frequency.value = 5 + Math.random()*2;
    const lfoG = ctx.createGain(); lfoG.gain.value = 0.006; lfo.connect(lfoG); lfoG.connect(src.frequency);

    const pre = ctx.createGain(); pre.gain.value = gain;
    const [f1,f2,f3] = VOWELS[v] || VOWELS.ah;
    const b1 = bandpass(ctx, f1*pitch, 20), b2 = bandpass(ctx, f2*pitch, 40), b3 = bandpass(ctx, f3*pitch, 60);
    const nasal = bandpass(ctx, 250, 8); // nasal resonance
    src.connect(pre); pre.connect(b1); pre.connect(b2); pre.connect(b3); pre.connect(nasal);
    const sum = ctx.createGain(); b1.connect(sum); b2.connect(sum); b3.connect(sum); nasal.connect(sum);
    const asp = noise(ctx); const hp = ctx.createBiquadFilter(); hp.type = "highpass"; hp.frequency.value = 6000; asp.connect(hp); hp.connect(sum); // aspiration

    const env = ctx.createGain(); env.gain.value = 0.0001; sum.connect(env); env.connect(this.master);
    // coarticulation-friendly ADSR
    env.gain.setValueAtTime(0.0001, t);
    env.gain.exponentialRampToValueAtTime(1.0, t + Math.min(0.015, d*0.2));
    env.gain.setValueAtTime(1.0, t + Math.max(0.01, d*0.7));
    env.gain.exponentialRampToValueAtTime(0.0001, t + d);

    src.start(t); lfo.start(t);
    src.stop(t + d); lfo.stop(t + d);
  }
  renderConsonant(ph, t, d, pitch, gain = 0.12) {
    const ctx = this.ctx; const n = noise(ctx);
    const bp = bandpass(ctx, CONS_CENTERS[ph] || 2000, 100);
    const g = ctx.createGain(); g.gain.value = gain; n.connect(bp); bp.connect(g); g.connect(this.master);

    const atk = Math.min(0.006, d*0.3), rel = Math.min(0.03, d*0.5);
    g.gain.setValueAtTime(0.0001, t);
    g.gain.exponentialRampToValueAtTime(gain, t + atk);
    g.gain.exponentialRampToValueAtTime(0.0001, t + d - rel);

    if (["m","n","l","r","v","z","w","y","jh","zh","ng"].includes(ph)) {
      const osc = ctx.createOscillator(); osc.type = "triangle"; osc.frequency.value = 100 * pitch;
      const vg = ctx.createGain(); vg.gain.value = 0.06; osc.connect(vg); vg.connect(this.master);
      osc.start(t); osc.stop(t + d);
    }
    n.start(t); n.stop(t + d);
  }
}
function bandpass(ctx, freq, Q) { const f = ctx.createBiquadFilter(); f.type = "bandpass"; f.frequency.value = freq; f.Q.value = Q; return f; }
function noise(ctx) { const b = ctx.createBuffer(1, ctx.sampleRate*2, ctx.sampleRate); const d = b.getChannelData(0); for (let i=0;i<d.length;i++) d[i] = (Math.random()*2-1)*0.6; const s = ctx.createBufferSource(); s.buffer=b; s.loop=true; return s; }
function isVowel(ph){ return Object.prototype.hasOwnProperty.call(VOWELS, ph); }

# client/chango/wakeword/detector.js
// Tiny mel-template DTW matcher for wake word; expects short-cut template vectors
import { bus } from "../core/eventBus.js";
import { MFCC } from "../audio/mfcc.js";

export class WakeWordDetector {
  constructor({ name = "lolo", thresh = 0.72 } = {}) {
    this.name = name; this.thresh = thresh; this.mfcc = new MFCC(); this.templates = [];
  }
  enroll(templateFrames) { this.templates.push(templateFrames); }
  score(seq, tmpl) { // cosine mean over aligned frames (naive length match)
    const L = Math.min(seq.length, tmpl.length); let s = 0;
    for (let i = 0; i < L; i++) s += this.mfcc.cosine(seq[i], tmpl[i]);
    return s / L;
  }
  detect(seq) {
    let best = -1; for (const t of this.templates) best = Math.max(best, this.score(seq, t));
    if (best >= this.thresh) bus.emit("wake:hit", { phrase: this.name, score: best });
  }
}

# client/chango/stt/webspeech.js
import { bus } from "../core/eventBus.js";
export class WebSpeechSTT {
  constructor() { this.rec = null; this.active = false; }
  start() {
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) { bus.emit("stt:unavailable"); return; }
    this.rec = new SR(); this.rec.continuous = true; this.rec.interimResults = true; this.rec.onresult = (e) => {
      const i = e.resultIndex, r = e.results[i];
      bus.emit("stt:result", { text: r[0].transcript, final: r.isFinal });
    };
    this.rec.onend = () => { if (this.active) this.rec.start(); };
    this.rec.start(); this.active = true;
  }
  stop() { try { this.rec && this.rec.stop(); } catch {} this.active = false; }
}

# client/chango/ui/adapter.js
// Headless adapter: binds to existing DOM via data-chango-* without altering layout
import { bus } from "../core/eventBus.js";

export class UIAdapter {
  constructor() {
    this.el = {
      enable: q('[data-chango-enable]'),
      speak:  q('[data-chango-speak]'),
      stop:   q('[data-chango-stop]'),
      text:   q('[data-chango-text]'),
      status: q('[data-chango-status]')
    };
  }
  mount({ speakFn, stopFn, unlockFn }) {
    this.el.enable && this.el.enable.addEventListener("click", unlockFn);
    this.el.speak  && this.el.speak.addEventListener("click", () => speakFn(this.text()));
    this.el.stop   && this.el.stop.addEventListener("click", stopFn);
    bus.on("status", s => this.status(s));
    bus.on("vad:start", () => this.status("listening…"));
    bus.on("vad:stop", () => this.status("idle"));
    bus.emit("status", "idle");
  }
  text(){ return this.el.text ? (this.el.text.value || this.el.text.textContent || "") : ""; }
  status(s){ if (!this.el.status) return; this.el.status.textContent = s; }
}
function q(sel){ return document.querySelector(sel); }

# client/chango/bootstrap.js
// Entry: keeps UI intact; only behavior added. Requires user gesture to unlock audio.
import { bus } from "./core/eventBus.js";
import { ctxPool } from "./audio/contextPool.js";
import { VAD } from "./audio/vad.js";
import { MFCC } from "./audio/mfcc.js";
import { prosodyPlan } from "./tts/prosody.js";
import { accentize } from "./accent/engine.js";
import { FormantSynth } from "./tts/formantSynth.js";
import { WakeWordDetector } from "./wakeword/detector.js";
import { WebSpeechSTT } from "./stt/webspeech.js";
import { UIAdapter } from "./ui/adapter.js";

const ui = new UIAdapter();
const vad = new VAD();
const mfcc = new MFCC();
const tts = new FormantSynth();
const stt = new WebSpeechSTT();
const wake = new WakeWordDetector({ name: "lolo" });

// minimal wake template (fake example): 12 frames of 13-d MFCC zeros → user should enroll real template later
wake.enroll(Array.from({ length: 12 }, () => new Float32Array(13)));

function unlock() {
  ctxPool.unlock().then(() => bus.emit("status", "ready")).catch(() => bus.emit("status", "error: audio"));
}

async function speak(text) {
  if (!text || !text.trim()) { bus.emit("status", "nothing to say"); return; }
  // Prosody → phonemes (very light map here)
  const plan = prosodyPlan(text);
  const phonemes = wordsToPhones(plan);
  const acc = accentize(phonemes, "neutral");
  await tts.speak(timeline(acc), { rate: 1, pitch: 1, volume: 1 });
  bus.emit("status", "idle");
}

function stop() {
  ctxPool.stop(); bus.emit("status", "stopped");
}

function wordsToPhones(plan) {
  // minimal G2P fallback
  const dict = { hello:["h","eh","l","ow"], world:["w","er","l","d"], chango:["ch","aa","ng","ow"], jarvis:["jh","aa","r","v","ih","s"] };
  const out = [];
  for (const unit of plan) {
    const w = unit.word.toLowerCase().replace(/\*|_/g, "");
    const phs = dict[w] || fallbackGrapheme(w);
    for